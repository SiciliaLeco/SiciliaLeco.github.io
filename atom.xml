<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sicilia Lee&#39;s blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-04-05T03:35:01.393Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Sicilia Lee (李颀琳）</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2022Fall CS DIY申请总结</title>
    <link href="http://example.com/2022/04/02/summary2022/"/>
    <id>http://example.com/2022/04/02/summary2022/</id>
    <published>2022-04-02T03:32:26.000Z</published>
    <updated>2022-04-05T03:35:01.393Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2022Fall-CS-DIY申请总结"><a href="#2022Fall-CS-DIY申请总结" class="headerlink" title="2022Fall CS DIY申请总结"></a>2022Fall CS DIY申请总结</h1><p>如果“申请季”的定义是指从选校到拿到offer，那我的申请季已经持续了快要一年了。和升学有关的焦虑好像一直缠着我，政策的变动、学校的通知、以及各种各样的小道消息似乎每天都在压榨我的大脑。好在现在所有的糟心事好像已经基本结束，我也终于有心思再去看电影和出去玩了。这篇文章会简单记录一下我留学申请的心路历程和一些想法，如果有什么想问的可以直接留言或者找我～</p><h2 id="0-为啥要出国"><a href="#0-为啥要出国" class="headerlink" title="0. 为啥要出国"></a>0. 为啥要出国</h2><p>我产生出国的想法，应该是在看UW或者CMU的网课的时候，突然非常向往这样的上课模式。那个时候我正好从高中三年的无限摆烂和自我感动中爬出来，回望满身泥泞和空空的口袋，我决定早点开始规划出国。虽然后面我又开始摆烂，很多计划中的事儿都没照常完成，但还是勉强凑出了一份能提交的个人简历。</p><h2 id="1-个人背景"><a href="#1-个人背景" class="headerlink" title="1. 个人背景"></a>1. 个人背景</h2><blockquote><p>三维：CQU CS专业 3.8/4.0，NUS交换 4.5/5.0，托福108 = R27 + L28 + S25 + W28，GRE 154 + 169 + 4.0.<br>科研和项目：一段在vintage group@NUS（CV，眼球三维视线检测），一段本校SRTP（CV，人群检测），大四正在做的课题（CV，三维点云配准），一些乱七八糟的硬件开发（FPGA卷积加速，高层次综合计算）<br>实习：校企公司Java开发，感觉不值得一提呀<br>推荐信：IEEE F科研推 x 1，本校科研推 x 1，本校课程推 x 3，强度应该都还可以<br>奖项：本校的各种奖学金和荣誉称号，国模国二</p></blockquote><p>关键信息：本人大学期间基本都在卷CV，但是卷的成果又不是很好，所以被一些CV强校拒（痛失我爱的ucsd）；其他一些硬件项目虽然做的不多，但是可能与部分学校（uiuc、duke）比较契合，所以也能拿到录取.</p><h2 id="2-申请情况"><a href="#2-申请情况" class="headerlink" title="2. 申请情况"></a>2. 申请情况</h2><p>我申请的时候主要分了4类，即彩票-冲刺-主申-保底，难度依次递减。</p><ul><li>彩票：UCSD@CS75 ☔️, CMU@MSIN ☁️, UMich@CSE, UCB@EECS MEng </li><li>冲：CMU@ECE, Gatech@CSE☀️, UCSD@EC79, UIUC@ECE MEng☀️</li><li>主申：Duke@ECE MS☀️, UCI@MCS☀️, NUS@MSCS </li><li>保底：RICE@MCS☀️, USC@game develop, USC@CS(general)☀️ , NEU@MSCS☀️</li></ul><blockquote><p>☔️：reject, ☁️: waitlist, ☀️:admission</p></blockquote><h2 id="3-申请策略"><a href="#3-申请策略" class="headerlink" title="3. 申请策略"></a>3. 申请策略</h2><p>虽然说自己的研究生生涯是就业导向为主的，但我还是想在研究生期间多学习一些CV track的技术。毕竟就算不能深入学CV，能有机会去上大牛的课还是非常棒的体验～所以在选校的时候，我主要参考的是cs ranking的总排名以及CV方向的排名。具体的话，我会考虑学校在如下几个维度的特征：</p><p><strong>(1) 专业</strong><br>申请的专业的话还是以CSE或者CS为主，有的学校ECE<strong>不错</strong>的话也会纳入考虑范围。这里“不错”的概念是不会有太多硬件的必修课，学生有足够的精力去学习CS核心课程。举个例子，UMich、UW以及Cornell的ECE项目都有比较多的必修硬件课，对于CS专业的学生并不是特别友好。比较友好的ECE项目有 UIUC、UCSD、CMU和Duke，其中UIUC基本上可以做到全CS课毕业。</p><p><strong>(2) 地理位置</strong><br>可以看到我的选校列表有俩特点，第一是加州的学校比较多，再一个是纽约的学校数量为0。这个就是我在地理位置上的偏好了：我对nyc比较无感，但是一直对加州非常神往（《重庆森林》打钱！（我在说啥））</p><p><strong>(3) 学校在业界的认可度</strong><br>我自己的职业规划是硕士毕业以后在美国找工作，所以不会面临一毕业就回国秋招的问题。这样的话，我似乎更应该考虑的是学校在美国工业界的认可度。并且我就算是晚几年回国也是走社招了，学历的问题可能就不再是那么重要，更重要的是工作经历了。基于以上这两点，我主要还是选择适合留美找工的硕士项目（关键词：既发CPT又发OPT，有coop，cs排名好，有target company）</p><p>计算机专业排名我主要参考的是<a href="http://csrankings.org">CS Ranking</a>，这个排名主要是学术声誉，接受某一研究方向下学校排名的查询。最好不要在简中互联网搜排名，否则你或许只能看到天花乱坠的中介广告。</p><p><strong>(4) 性价比</strong><br>这里主要是考虑的投入回报比。有的学校学费太贵，但是最后的毕业去向数据和其他学校大差不差，我就没有选择。不过这个问题的考虑可以在拿到offer以后再考虑，说不定学校给你奖学金，或者有RA、TA position呢？</p><p>在选校的时候，有一点很重要：项目的bar并不能代表这个项目的好坏。评判一个项目的好坏有多个指标，且主观性极强。不必因为这个项目很难就将它设成自己的梦校，也不要觉得“这学校申请有手就行，我随便准备一下”。自己的需求和研究生目标是最重要的，选校的时候，只要是你认为这所学校能给你带来你需要的东西，就可以去尝试。</p><p>还有一点就是，任何人的建议只是参考，不要完全听信。举个例子，前期我在了解GT的时候，被学长告知重大往届基本没有录取到的。但是我还是莽了一把，然后很幸运收到了offer。反正就是几百块申请费的事儿嘛，说不定就刮中彩票了呢？（笑）</p><h2 id="4-时间安排"><a href="#4-时间安排" class="headerlink" title="4. 时间安排"></a>4. 时间安排</h2><blockquote><p>2019.3：转专业<br>2019.7：暑假在武汉找了几家留学机构咨询，上了一个无聊的托福培训班…<br>2019.10: 联系了本校一个RL方向的导师，但后来没跟着做下去<br>2019.11：第一次考了托福97分<br>2020上半年：疫情荒废学业（但学会了做菜）<br>2020.6：SRTP<br>2020.9: 拿到NUS交换资格<br>2020.11: 国模国二<br>2020.12: 第一次考GRE 315分（我真的会吐）<br>2021上半年：NUS交换，科研，<em>开始攒留学论坛的积分</em>（。。。。）<br>2021.6: 第二次考GRE 319分<br>2021.7: 回学校肝水实习，开始选校<br>2021.9: 第二次考托福108分，开始PCR的课题<br>2021.10: 速成GRE 323分，联系推荐信老师，确定最终选校名单<br>2021.11: 开始写文书，自己写初稿 -&gt; native speaker 改 -&gt; 同学帮改<br>2021.12: 开始投递<br>2021.2: 开始痛苦等待</p></blockquote><p>可以看到，我在大三大四，尤其是大三下真的忙得非常痛苦，原因就是语言考得太晚了。我一直以为从新加坡回来以后，英语读写能力会全方位提升，但实际上并不会这么明显。这样的话，我真的会劝学弟学妹们有机会的话大一大二就考语言，这样可以多留点时间在科研上努力。</p><p>这段时间也是我EMO频率最高的时候，大三下的时候在NUS感觉好忙，不过Stefan那边科研机会对于我的帮助真的超级大。大四上的时候，一个人投15个项目压力有点儿大了，文书咋都写不出来欲哭无泪，要面试的学校没地方面（感谢yxy带我借用华为会议室，还蹭了几次工卡吃饭）每天到了晚上就会开始烦躁、怀疑自己的能力。我申请季开始的时候买了《塞尔达传说：旷野之息》，到了接到offer的时候游戏时长已经有300h了，这些时间都是我感到焦虑的时候靠游戏发泄的证明。（但是真的好好玩，谢谢你任天堂）</p><p>我接到第一个offer大概是在3月的时候才有。在这之前我已经心灰意冷，开始思考春招的事情。奈何找实习也是出师不利，导致我的整个二月份都在emo中默默度过。收到第一个offer的那天，我跑去了一家收藏很久的日料店饱餐了一顿，然后我以为自己会保持快乐。但很快，我就失去了这种快乐的感觉， 因为我意识到，后面还要面临更多这样的一个一个的节点。</p><h2 id="5-一些DIY申请的tips"><a href="#5-一些DIY申请的tips" class="headerlink" title="5. 一些DIY申请的tips"></a>5. 一些DIY申请的tips</h2><h3 id="5-1-语言考试"><a href="#5-1-语言考试" class="headerlink" title="5.1 语言考试"></a>5.1 语言考试</h3><p>语言考试我自己做的不太好，主要是准备得时间短、很仓促，GRE考到第三次才上320（阅读苦手）不过托福的话我还是比较努力的在学，在网上收了很多资料，自己看了以后觉得有奇效，准备了一个多月就出分啦。</p><p>这里留一些我认为不错的语言考试资料，下载的话可以在下面的链接里面找百度网盘。</p><ul><li>GRE：<ul><li>阅读：强烈推荐闫晨晨老师，我当时来不及了没看完，但是感觉得到自己看网课以后的进步</li><li>模考：皇冠GRE（不需要买它的答案，需要的话可以直接给我留言）</li><li>数学：张巍，做完基本上169+没有问题，剩下的1分交给细心和解题速度</li></ul></li><li>托福<ul><li>口语：Fiona老师的网课（我知道这个资源很紧俏，但我的网盘里有嘿嘿嘿）</li><li>写作：黎老师28写作，据说是上完课就是28分，我还真是，就…有点玄学吧</li></ul></li></ul><p>资料下载：<a href="https://www.1point3acres.com/bbs/thread-797271-1-1.html">https://www.1point3acres.com/bbs/thread-797271-1-1.html</a></p><h3 id="5-2-文书"><a href="#5-2-文书" class="headerlink" title="5.2 文书"></a>5.2 文书</h3><p>其实我到现在都不知道文书在申请中到底有多重要，有的学校我自认为文书很好但是没有给我正面反馈，有的学校我ddl前赶稿写得很仓促，却也能拿到录取。</p><p>对于CS / ECE混申、就业导向和授课导向混申的我，写文书的时候也得针对不同的情况写不同学校偏好的文书。虽然大框架都差不多，但是里面的细节，比如why school以及why me的部分都要重写。我当时给每个学校的文书大致分了类，如下图：<br><img src="/2022/04/02/summary2022/IMG_1292.PNG" alt="IMG_1292.PNG"><br>文书我前前后后写了快两个月，先是自己打一个初稿，然后去<a href="https://www.fiverr.com/categories/writing-translation?source=hplo_cat_sec&amp;pos=3">fiverr</a>上找了三四个老外帮我改语用和语法。其中有一个土耳其的老哥，帮我改了ECE的文书，写得非常精简凝练，价格也比较良心。在老外修改好了以后，我又发给谢顺、sbw和yxy反复看了一看，最后针对每个学校修改有区别的部分，然后才提交。</p><p>写文书应该是申请里面最痛苦的一关啦，过了这关以后，你基本上就可以躺着等offer了。关于文书的具体写法和框架，我觉得一两句讲不完，后面有机会的话我再写一篇吧，如果有人需要的话(^_^)v</p><h3 id="5-3-心态"><a href="#5-3-心态" class="headerlink" title="5.3 心态"></a>5.3 心态</h3><p>整体上来说我是一个极端的悲观主义者，并且容易给自己制造焦虑。最开始的时候，很怕自己被梦校拒，所以不敢想象收到结果时候自己的心态会怎样。但是随着时间的等待，我对申请结果的执念变少了一些，焦虑也慢慢转移到了别处。</p><p>在申请季，被梦校拒其实是很正常的事情，毕竟大家也不会把很容易申请的学校标成自己的dream吧？所以有挑战的事情失利是很正常的。ucsd的cs75应该是我的梦中之梦，因为ucsd有非常好棒的cv方向的prof，和我本科做过的内容也非常接近。再加上我对加州的美好滤镜，ucsd就成了我申请季中非常向往一个地方。忘了后来是怎么就慢慢想通了，没有像以前那样执念于cmu或者ucsd，对所有的学校都保持一个平衡的心态。最后收到sd的rejection，我好像也没有不开心，然后日记里写了如下的话：<br><img src="/2022/04/02/summary2022/A9ACA078-146B-4189-B77E-D708CFF1F5E7.png" alt="A9ACA078-146B-4189-B77E-D708CFF1F5E7.png"></p><h2 id="6-感想"><a href="#6-感想" class="headerlink" title="6. 感想"></a>6. 感想</h2><p>发挥才智，则锋芒毕露；凭借感情，则流于世俗；坚持己见，则孤独无友；总之，人世难居。</p><h2 id="7-很重要的一栏：致谢"><a href="#7-很重要的一栏：致谢" class="headerlink" title="7. 很重要的一栏：致谢"></a>7. 很重要的一栏：致谢</h2><p>我感觉在毕业设计里面不太好写出如此详细的致谢，所以就这边完整写咯。下面都是一些矫情话，如果你的脚趾头已经开工了，可以略过这一段～</p><p>首先是感谢我妈一直无条件支持我出国的各种事情，没觉得我是在开玩笑或者三分钟热度。以前我妈老在手机上看织毛衣教程和电视剧，我上大学以后，她看的内容都变成了美国留学局势分析，也挺不容易的～不过也应该趁机学了不少英语吧，这波不亏！</p><p>然后是身边一些很棒的朋友，鼎力支持我的留学事业。yxy让我把他放在第一个，那我先夸夸他对我留学进展的全程关注和帮助。申请季他帮我收集了不少留学信息，还能背诵我的选校列表，属实是温暖了四季了。sbw一直算是我的军师，佐治亚理工就是他推荐我去申请的。虽然跟我有时差，但是每次给他看文书和套磁信都会很认真的给我反馈（有一次甚至直接帮我写了呜呜呜）谢顺在申请季期间成了我的心理咨询师，让我很多emo的瞬间转化成了”笑得想死”的状态。还有csh、海龙大哥以及我的室友们，和他们的交谈让我思路更清晰，对留学的想法也逐步成熟。</p><p>申请季我还遇到了很多来自其他学校的同学，并成为了不错的朋友。大家都在申请过程中给了我非常重要的指点，让我在第一次弄留学申请的时候就能规避很多麻烦事儿。朋友们最后也都如愿收到了自己喜欢的学校的offer，我们可以到时候一起线下面基啦！</p><p>最后的最后，还是要谢谢自己在无数个想要放弃的瞬间都选择坚持，并且在无数次怀疑自己以后还是选择相信自己。现在看来，我本人还是挺靠得住的。</p><p>谢谢你愿意看到这里！如果上面的一些申请感想和经验能够帮助到你或者带来一些小小的感想，那就再好不过啦。祝愿你生活愉快 ;-)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;2022Fall-CS-DIY申请总结&quot;&gt;&lt;a href=&quot;#2022Fall-CS-DIY申请总结&quot; class=&quot;headerlink&quot; title=&quot;2022Fall CS DIY申请总结&quot;&gt;&lt;/a&gt;2022Fall CS DIY申请总结&lt;/h1&gt;&lt;p&gt;如果</summary>
      
    
    
    
    <category term="Solutions" scheme="http://example.com/categories/Solutions/"/>
    
    
  </entry>
  
  <entry>
    <title>MacBook Pro 2019维修全过程记录</title>
    <link href="http://example.com/2022/03/28/MBPfix/"/>
    <id>http://example.com/2022/03/28/MBPfix/</id>
    <published>2022-03-28T03:32:26.000Z</published>
    <updated>2022-04-01T13:44:10.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MacBook-Pro-2019六国问题维修全过程记录"><a href="#MacBook-Pro-2019六国问题维修全过程记录" class="headerlink" title="MacBook Pro 2019六国问题维修全过程记录"></a>MacBook Pro 2019六国问题维修全过程记录</h1><h3 id="1-Problem-Restate"><a href="#1-Problem-Restate" class="headerlink" title="1. Problem Restate"></a>1. Problem Restate</h3><p>前几天的时候一直没有高强度地使用自己的笔记本，但是偶尔会出现自动关机的情况，但是并没有报错或者死机，所以也就没有在意。但是周六早上我看了一早上的编译原理网课（在b站看，后来和同学聊到，猜测可能是adobe flash的锅）下午的时候突然开始反复自动重启。在关机之前，风扇会突然大声转动，然后马上关机。 touch bar再重启时不亮，主板部分发烫，再次开机的时候出现六国问题：<br><img src="/2022/03/28/MBPfix/72DE8D93-0C85-4A58-9A82-00CB2B3D9334.png" alt></p><p>尝试重启，出现如下图所示的问题：<br><img src="/2022/03/28/MBPfix/CDD4CE7C-6653-45CA-8630-AB6D9C9A5198.png" alt></p><p>当时因为不能正常保持开机，所以刚开始最怀疑的还是主板的问题。且当时touch bar自动熄灭了，充分相信是主板部分被烧坏了。心急如焚，当时以为要花半个机子的价钱维修主板（某维修店原话），心都碎了。。</p><p>看了下报错信息，里面发现了panic以及checkins，初步判定是操作系统的锅。我自己特别喜欢删mbp里面的Containers之类的文件减少存储占用，猜测可能误删了相关文件而自己不知道。<br>   <img src="/2022/03/28/MBPfix/6CAF4025-7C68-48A6-9F4E-9B81024A1B2C.png" alt="把我的电脑都吓回默认壁纸了。。"></p><h3 id="2-可能的原因-amp-解决方案"><a href="#2-可能的原因-amp-解决方案" class="headerlink" title="2. 可能的原因&amp;解决方案"></a>2. 可能的原因&amp;解决方案</h3><p>尝试通过简单的诊断工具自检电脑情况。<br>方法1：开机时按住Command + R进入安全模式，如果在安全模式下可以正常进行说明基本上是软件的问题，比如说app与os版本不兼容。<br>方法2：开机时按住D进入诊断模式，通过Apple自己的诊断工具对硬件做简单诊断。如果诊断有问题的话可以考虑维修点拆机看看；如果没有的话，倾向于软件方面的问题。（后来咨询维修人员称并不能检查出所有的硬件问题，这一步仅供参考）</p><p>我自己在重启、开机尝试多次以后，电脑有短短地正常运作了一阵子，并且touch bar竟然亮起来了，这时我基本排除了硬件问题，感觉是更新的MacOS Monterey 12.3 与电脑上的某些软件不能兼容。前阵子装了很多unauthorized 的软件，比如居家办公软件、梯子、激活版Adobe Premiere等等……怀疑版本不能兼容了。</p><p>解决方案：</p><ol><li>首选是使用Time Machine中的数据回到以前的版本，但由于本人没有使用此功能做备份，并且想使用Monterey新功能（设备间鼠标共享）所以放弃了这个方法</li><li>彻底重装软件系统，重新部署相关架构数据 （类似于开机重启的效果）但这个有一定风险，即自己的文件可能丢失。我的数据基本上都在iCloud里面因此影响不大，但是部署的代码编译环境就全没了，得重开。</li><li>直接粗暴换主板（在无法确认是否是硬件问题的情况下）我一开始想的是这个，但是后来tb自己亮了，让我坚信硬件没坏，因此省钱没有重装。</li></ol><h3 id="3-mbp使用（延长寿命）tips"><a href="#3-mbp使用（延长寿命）tips" class="headerlink" title="3. mbp使用（延长寿命）tips"></a>3. mbp使用（延长寿命）tips</h3><ol><li>散热问题，可以贴保护壳或者保护膜但是要保证其不堵住风扇出口</li><li>尽量不要下载未授权的软件，我记得暑假的时候我看一个“枪版”的托福网课弄得我的电脑风扇都快转掉了</li><li>不要长时间不休眠，多进入睡眠模式或者关机</li><li>插电使用</li><li>键盘膜还是要贴着防止滴水进去</li><li>不要盲目听从维修师傅的“拆机”，拆机会使得你的电脑在回收的时候价格下跌，并且有可能你的电脑问题并不是扎根在主板上。比如我，最后看上去就是一个软件兼容性的问题。</li></ol><p>在此许愿我的电脑不要再坏了呜呜呜</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MacBook-Pro-2019六国问题维修全过程记录&quot;&gt;&lt;a href=&quot;#MacBook-Pro-2019六国问题维修全过程记录&quot; class=&quot;headerlink&quot; title=&quot;MacBook Pro 2019六国问题维修全过程记录&quot;&gt;&lt;/a&gt;MacBo</summary>
      
    
    
    
    <category term="Solutions" scheme="http://example.com/categories/Solutions/"/>
    
    
  </entry>
  
  <entry>
    <title>Neural Unsigned Distance Field 解读</title>
    <link href="http://example.com/2022/03/05/nudf/"/>
    <id>http://example.com/2022/03/05/nudf/</id>
    <published>2022-03-05T03:32:26.000Z</published>
    <updated>2022-03-12T08:11:41.062Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Neural-Unsigned-Distance-Field-解读"><a href="#Neural-Unsigned-Distance-Field-解读" class="headerlink" title="Neural Unsigned Distance Field 解读"></a>Neural Unsigned Distance Field 解读</h1><h2 id="0-基本思想"><a href="#0-基本思想" class="headerlink" title="0. 基本思想"></a>0. 基本思想</h2><p>Implict Function Learning(IFL) 的核心思想是基于学习将空间中的连续点分类（classify）成inside 和 outside 两种。对于点的特征，可以用Occupancy或者SDF value 来衡量。因此IFL的输出可以是连续的空间表面。但是传统的IFL有一个问题，就是是重建的物体必须是封闭的，当物体不封闭时，就不能区分出查询点到底是在物体的内部还是在外部。（比如car，cylinder等）因此作者提出了NDF来解决这个问题。</p><p>NDF直接预测了UDF（unsigned distance field）该变量是点到表面的无符号距离。通过距离就可以很好地来探索非闭合的物体。并且NDF还可以用于2D shape representation，这在之前是不可能用SDF或者Occupancy表达的。</p><p>本文的创新主要是引入了NDF，NDF不需要对mesh进行预结算，在很多数据集上都达到了SOTA。</p><p>NDF会带来一些问题：</p><ol><li>预测的无符号距离函数没有符号，在曲面上不可微</li><li>大多数生成点、网格和渲染图像的算法都只用SDF，没有关于无符号的后处理算法。</li></ol><h2 id="1-体素化-voxelization"><a href="#1-体素化-voxelization" class="headerlink" title="1. 体素化 voxelization"></a>1. 体素化 voxelization</h2><p>体素化通俗地说就是得到点云物体的乐高模型（体素化的操作可以对模型进行简化，从而得到<strong>均匀</strong>的网格。对点云进行体素化的处理，算法的主要流程是：<br>首先，计算出点云在X、Y、Z三个方向数据坐标的最大值和最小值，从而确定长宽高。这一步骤得到的初始体素可以包含所有的点云数据。<br>建立了基本体素后，进行划分，使用Bresenham算法那剔除初始体素中无效的体素，剩余的就是点云体素化以后的结果。</p><h3 id="1-1-off文件格式"><a href="#1-1-off文件格式" class="headerlink" title="1.1 .off文件格式"></a>1.1 .off文件格式</h3><p><code>.off</code> 是一种3D文本格式，通过定义点、线、面的方式来描述3D物体。一般可以用纯文本的格式打开。这一部分对<code>.off</code>文件格式进行讲解。有多种形式，这里用手边有的ModelNet40数据为例：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">OFF</span><br><span class="line">11634 14640 0</span><br><span class="line">19.6172 118.1 140.1</span><br><span class="line">10.5766 108.108 136.696</span><br><span class="line">18.9919 111.778 136.696</span><br><span class="line">.....</span><br><span class="line">3 480 243 481</span><br><span class="line">3 481 243 482</span><br><span class="line">3 462 483 484</span><br><span class="line">.....</span><br></pre></td></tr></table></figure><br>第一行表示的是OFF格式，所有的.off文件都是这样开头的。第二行，表示的是当前这个三维几何问题顶点数目、面数目，边数目。边数目为0说明是点云的文件。第三行到第3+N行（N为点的总个数）后面剩下的每一行，表示的是当前的第i个面由3个点组成，并且附上了这三个点的下标。读取.off文件并返回点面集合的代码如下:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_off</span>(<span class="params">filename</span>):</span></span><br><span class="line">    points = []</span><br><span class="line">    faces = []</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        first = f.readline()</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(first) &gt; <span class="number">4</span>):  <span class="comment"># Too handle error in .off like OFF492 312 0</span></span><br><span class="line">            n, m, c = first[<span class="number">3</span>:].split(<span class="string">&#x27; &#x27;</span>)[:]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            n, m, c = f.readline().rstrip().split(<span class="string">&#x27; &#x27;</span>)[:]</span><br><span class="line">        n = <span class="built_in">int</span>(n)</span><br><span class="line">        m = <span class="built_in">int</span>(m)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            value = f.readline().rstrip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            points.append([<span class="built_in">float</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> value])</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            value = f.readline().rstrip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">            faces.append([<span class="built_in">int</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> value])</span><br><span class="line">    points = np.array(points)</span><br><span class="line">    faces = np.array(faces)</span><br><span class="line">    <span class="keyword">return</span> points, faces</span><br></pre></td></tr></table></figure><br>在本作中，也是使用了<code>.off</code>文件进行了一系列转换最终得到了体素化的结果。下面一部分就具体讲怎么做体素化的。</p><h3 id="1-2-dataprocessing"><a href="#1-2-dataprocessing" class="headerlink" title="1.2 /dataprocessing"></a>1.2 /dataprocessing</h3><p>从对NDF算法的理解上，我们知道encoder的输入是有面和点的，因此只提供点云的数据是完全不够的。所以，这个文件夹下的代码文件目的是为了对点云数据集进行预处理，得到点对应的面， 从而去求他的unsigned distance的值。对于数据的处理主要分为以下的内容：</p><p>(1) scale的部分。<br>我理解的scale目的就是对原始的点云数据（raw data）做normalize，并且点的数量也变得稀疏。这一部分的核心代码是<code>convert_to_scaled_off.py</code>。</p><p>(2)对点云做边界采样的部分。<br>这一部分的内容比较类似Occupancy Networks 中的做法，即在对象的三维边界体中随机采样点，对于第i个样本，采样K个点，然后评估这些位置的小批量损失。</p><p>这一部分的核心代码是<code>boundary_sampling.py</code>函数。这一部分首先是通过给的sigma参数对于原始的点云数据进行采样，然后通过igl库里自带的signed_distance函数生成预测的距离函数的ground truth。这一部分的代码返回了三个内容，df（ground truth of ndf），grid_coord以及points（采样的点）。作者在github的<a href="https://github.com/jchibane/ndf/issues/19">issue</a>中对<code>grid_coord</code>进行了解释，称是让pytorch的<code>grid_sample</code>函数作为输入使用。<br>本部分记录在<code>.npz</code>文件中的内容如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.savez(out_file, points=boundary_points, df = df, grid_coords= grid_coords)</span><br></pre></td></tr></table></figure></p><p>(3)对点云做体素化。<br>这一部分的核心代码是<code>voxelized_pointcloud_sampling.py</code>。首先构建出初始的网格点grid_points，后续用来填充这一部分的occupancy值（从而可以构建出点云的体素化）在Occupancy Networks这篇论文里，有这样的解释：</p><blockquote><p>For extracting the isosurface corresponding to a new observation given a trained occupancy network, we introduce Multiresolution IsoSurface Extraction (MISE), a hierarchical isosurface extraction algorithm. By incrementally building an octree MISE enables us to extract high resolution meshes from the occupancy network without densely evaluating all points of a high-dimensional occupancy grid.</p></blockquote><p>我个人认为ndf这里也是类似的处理方法，即使用了空间二叉树（也就是代码里的<a href="https://zhuanlan.zhihu.com/p/127022333">kdTree</a>）来计算了所谓的isosurface。这个surface后面会被用在训练里。本部分得到的内容记录如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.savez(out_file, point_cloud=point_cloud, compressed_occupancies = compressed_occupancies, bb_min = cfg.bb_min, bb_max = cfg.bb_max, res = cfg.input_res)</span><br></pre></td></tr></table></figure></p><h2 id="2-模型训练"><a href="#2-模型训练" class="headerlink" title="2. 模型训练"></a>2. 模型训练</h2><h3 id="2-1-数据集使用"><a href="#2-1-数据集使用" class="headerlink" title="2.1 数据集使用"></a>2.1 数据集使用</h3><p>在<code>/data/voxelized_data_shapenet.py</code>中，当调用get item函数的时候，返回的内容如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &#123;<span class="string">&#x27;grid_coords&#x27;</span>:np.array(coords, dtype=np.float32),<span class="string">&#x27;df&#x27;</span>: np.array(df, dtype=np.float32),<span class="string">&#x27;points&#x27;</span>:np.array(points, dtype=np.float32), <span class="string">&#x27;inputs&#x27;</span>: np.array(<span class="built_in">input</span>, dtype=np.float32), <span class="string">&#x27;path&#x27;</span> : path&#125;</span><br></pre></td></tr></table></figure><br>这里的input是 <code>/voxelized_point_cloud_&#123;&#125;res_&#123;&#125;points.npz</code>这一类型的文件存储的，也就是体素化得到的Occupancies。其他的都是 <code>/boundary_&#123;&#125;_samples.npz</code>里得到的内容。详细的格式解读在1.2中有解释。</p><h3 id="2-2-模型构建"><a href="#2-2-模型构建" class="headerlink" title="2.2 模型构建"></a>2.2 模型构建</h3><p>在<code>models/data/local_model.py</code>中写好了整个ndf算法的pytorch框架。encoder的输入是体素化的surface，用occupancy信息来作为encoder的输入，encoder的输出是6个维度的feature。已经知道了本作encoder的功能就是对point cloud以及它的zip code生成点云特征。decoder的任务就是通encoder得到的特征重建出点云。这里直接引用udf原文对于encoder和decoder的输入输出描述：</p><blockquote><p>Encoder: The input is voxelized and encoded by a 3D CNN as a multi-scale grid of deep features.<br>    Decoder: The task of the decoder is to predict the unsigned distance function (UDF) for points to the ground truth surface<br>对于之前没有理解的多feature处理方法，作者在这里是简单地使用torch.cat:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features = torch.cat((feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6)</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="2-3-模型训练"><a href="#2-3-模型训练" class="headerlink" title="2.3 模型训练"></a>2.3 模型训练</h3><p>代码中比较核心的部分，<code>training.py</code>中，介绍了训练的方法。主要看compute_loss函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">p = batch.get(<span class="string">&#x27;grid_coords&#x27;</span>).to(device)</span><br><span class="line">df_gt = batch.get(<span class="string">&#x27;df&#x27;</span>).to(device) <span class="comment">#(Batch,num_points)</span></span><br><span class="line">inputs = batch.get(<span class="string">&#x27;inputs&#x27;</span>).to(device)</span><br><span class="line">df_pred = self.model(p,inputs) <span class="comment">#(Batch,num_points)</span></span><br></pre></td></tr></table></figure><br>可以看到，送进去训练的是采样点p和体素化后的surface。在模型中，首先将voxelized surface $S$<code>input</code>送到encoder中，得到6个维度的feature。得到了feature以后，与sampled points $p$ <code>p</code>一同给到decoder中，通过公式$UDF(p,S) = min_{q\in S}||p-q||$求出预测的nueral unsigned distance field值。预测出的值，与udf的真值求loss损失函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_pred = self.model(p,inputs) <span class="comment">#(Batch,num_points)</span></span><br><span class="line">loss_i = torch.nn.L1Loss(reduction=<span class="string">&#x27;none&#x27;</span>)(torch.clamp(df_pred, <span class="built_in">max</span>=self.max_dist),torch.clamp(df_gt, <span class="built_in">max</span>=self.max_dist))<span class="comment"># out = (B,num_points)</span></span><br></pre></td></tr></table></figure></p><p>本部分的数据训练方法以及数据集中各个标签的使用：<br>对于encoder，输入通过preprocess计算出的occupancy（在代码中被标记为<code>input</code>）得到点云的feature。在得到了点云的feature 之后，将这一系列的点云特征（一共七个特征）输入到decoder中。在decoder中，通过feature和点云（被标记为<code>grid_coords</code>）求得最后的ndf值。<br>在得到了模型预测的ndf值后，与数据集中的<code>df</code>，ndf的真实值进行比较，然后真值和预测值的差异求出损失差值，对模型的计算进行反馈。</p><p>写到这里，感觉整个代码框架已经基本摸清了，我的下一部分工作就是把NDF和FMR框架进行整合。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Neural-Unsigned-Distance-Field-解读&quot;&gt;&lt;a href=&quot;#Neural-Unsigned-Distance-Field-解读&quot; class=&quot;headerlink&quot; title=&quot;Neural Unsigned Distance F</summary>
      
    
    
    
    <category term="Notes" scheme="http://example.com/categories/Notes/"/>
    
    
    <category term="Computer Graphics" scheme="http://example.com/tags/Computer-Graphics/"/>
    
    <category term="Computer Vision" scheme="http://example.com/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>Feature-metrics Registration 解读</title>
    <link href="http://example.com/2022/02/21/Feature-metrics%20Registration%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <id>http://example.com/2022/02/21/Feature-metrics%20Registration%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/</id>
    <published>2022-02-21T03:32:26.000Z</published>
    <updated>2022-03-03T14:43:14.608Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Feature-metrics-Registration-解读"><a href="#Feature-metrics-Registration-解读" class="headerlink" title="Feature-metrics Registration 解读"></a>Feature-metrics Registration 解读</h1><h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><p>FMR算法相比起ICP算法有两个创新之处，第一个是不需要对点云之间求出点与点之间的对应关系（correspondence）也不需要对数据进行标记就可以提取出特征。FMR算法中求特征的部分是无监督学习的。 </p><p>FMR算法主要分为两个部分。第一个分支的作用是对于输入的点云生成指定的特征。作者要求这里生成的特征是对旋转敏感的。在FMR算法中，由encoder来实现生成特征这一步骤。如何做无监督的学习呢？方法就是在encoder后面加上一个decoder。这个decoder会用生成的特征来还原一个点云。为了使encoder生成的点云更加正确，会用一个损失函数chamfer loss来计算生成的点云和原始点云的差异。从而反馈到encoder的参数中进行更新。这样encoder-decoder的架构，可以帮助整个算法得到比较准确的特征。 </p><p>第二个分支需要用到IC算法。分支2要对两个输入的特征计算projection error，通过这个error来参与IC算法来求出当前三维空间变换参数的迭代方向。也就是说，以点云P和Q作为输入，用第一分支中的encoder求出他们的特征。此时有一个初始化的三维旋转参数，也就是我们最后要求的旋转、平移矩阵。我们通过计算P与RQ+T的差异值error，开始做IC算法，求出来RT参数的偏移量，并加到上面，得到新的RT值。这一部分的检验会用到geometric loss，是用来检测预测出来的姿态与真实值的差异的。 </p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>ModelNet40数据格式：<br>由于读取了多个点云，假设数据集中的点云个数用<code>B</code>来表示。在训练中，<code>B</code>也是batch size。则输入数据的格式为：source点云<code>B x M x 3</code>,  target点云<code>B x N x 3</code>, transformation矩阵<code>B x 4 x 4</code>. 通过<code>/data/dataset.py</code>部分的代码读取了ModelNet40的数据，生成了对应的Source-Target-TransMatrix的数据集。从代码内容上看，点云之间的transformation似乎是通过他们的mesh关系等数据求解出来的，作者在<code>se_math</code>这个文件夹里面放了求解transformation的代码，待看。</p><h2 id="1-Models-py-部分"><a href="#1-Models-py-部分" class="headerlink" title="1. Models.py 部分"></a>1. Models.py 部分</h2><ol><li><p>Branch1：Encoder-Decoder建立<br>Encoder采用的是PointNet，其作用是对输入的点云做特征提取。输入：Points[B, N, 3]，输出：Features[B, K]. 其中，<code>K</code>是点云特征的维度，默认是1024。Encoder内部使用了两个<code>MLPNet</code>，<br>组成了Encoder-decoder机制以后，需要求解loss function，为了保证我们训练出来的Encoder是rotation attentive的，组合了source PC和target PC的loss结果一起反馈。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">decoder_out_f0 = self.decoder(f0)</span><br><span class="line">decoder_out_f1 = self.decoder(f1)</span><br><span class="line"></span><br><span class="line">p0_dist1, p0_dist2 = self.chamfer_loss(p0.contiguous(), decoder_out_f0)  <span class="comment"># loss function</span></span><br><span class="line">loss_net0 = (torch.mean(p0_dist1)) + (torch.mean(p0_dist2))</span><br><span class="line">p1_dist1, p1_dist2 = self.chamfer_loss(p1.contiguous(), decoder_out_f1)  <span class="comment"># loss function</span></span><br><span class="line">loss_net1 = (torch.mean(p1_dist1)) + (torch.mean(p1_dist2))</span><br><span class="line">loss_enco_deco = loss_net0 + loss_net1</span><br></pre></td></tr></table></figure></li><li><p>Branch2：Transformation estimate<br>首先看到<code>estimate_T()</code>方法，其作用就是预处理输入的训练数据，这里的<code>g0</code>是根据输入的点云个数生成的旋转平移矩阵的initial value。在得到了这个初值以后，进入到<code>ic_algo()</code>的部分。这个函数虽然叫IC，但是他也是同时处理了branch 1和branch2的工作。branch1 的内容就是利用decoder的输出和原始的点云计算Chamfer Loss。这一部分的核心代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p0_dist1, p0_dist2 = self.chamfer_loss(p0.contiguous(), decoder_out_f0)  <span class="comment"># loss function</span></span><br><span class="line">loss_net0 = (torch.mean(p0_dist1)) + (torch.mean(p0_dist2))</span><br><span class="line">p1_dist1, p1_dist2 = self.chamfer_loss(p1.contiguous(), decoder_out_f1)  <span class="comment"># loss function</span></span><br><span class="line">loss_net1 = (torch.mean(p1_dist1)) + (torch.mean(p1_dist2))</span><br><span class="line">loss_enco_deco = loss_net0 + loss_net1</span><br></pre></td></tr></table></figure></li></ol><p>完成了task1后，就进入了task2的内容，也就是核心的Inverse compositional 算法内容。在<code>SolveRegistration</code>的初始化部分，作者就初始化了一个dt 维度是<code>1x6</code>，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">delta = <span class="number">1.0e-2</span>  <span class="comment"># step size for approx. Jacobian (default: 1.0e-2)</span></span><br><span class="line">dt_initial = torch.autograd.Variable(torch.Tensor([delta, delta, delta, delta, delta, delta]))</span><br><span class="line">self.dt = torch.nn.Parameter(dt_initial.view(<span class="number">1</span>, <span class="number">6</span>), requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>从论文中可以得知，Task 2 将RT平移旋转矩阵转换成了$\theta = (v_1, v_2, v_3, t_1, t_2, t_3)$ ，而task 2 的重点内容就是求解出$\Delta \theta$. 求解的核心部分代码如下，对于每一句代码后注解了我的相关解释：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># task 2</span></span><br><span class="line">f0 = self.encoder(p0)  <span class="comment"># [B, N, 3] -&gt; [B, K]</span></span><br><span class="line"><span class="comment"># approx. J by finite difference</span></span><br><span class="line">dt = self.dt.to(p0).expand(batch_size, <span class="number">6</span>)  <span class="comment"># convert to the type of p0. [B, 6] #预备delta t，也就是变换量</span></span><br><span class="line">J = self.approx_Jac(p0, f0, dt)</span><br><span class="line"><span class="comment"># compute pinv(J) to solve J*x = -r</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    Jt = J.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, 6, K] J^T</span></span><br><span class="line">    H = Jt.bmm(J)  <span class="comment"># [B, 6, 6] J^T \cdot J</span></span><br><span class="line">    <span class="comment"># H = H + u_lamda * iDentity</span></span><br><span class="line">    B = self.inverse(H) <span class="comment"># (J^T \cdot J) -1</span></span><br><span class="line">    pinv = B.bmm(Jt)  <span class="comment"># [B, 6, K]</span></span><br></pre></td></tr></table></figure><br>注意到这里有一个调用approx_Jac的部分，是对应了论文里求解雅各布矩阵的流程。如下，标注了代码运行结果矩阵的尺寸，这里要注意的是，变成B x 6 x 4 x 4 是为了方便矩阵运算（为了满足矩阵做加减乘除运算而设定的）最后的输出返回结果是B x K x 6尺寸的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">approx_Jac</span>(<span class="params">self, p0, f0, dt</span>):</span></span><br><span class="line">        <span class="comment"># p0: [B, N, 3], Variable</span></span><br><span class="line">        <span class="comment"># f0: [B, K], corresponding feature vector</span></span><br><span class="line">        <span class="comment"># dt: [B, 6], Variable</span></span><br><span class="line">        <span class="comment"># Jk = (ptnet(p(-delta[k], p0)) - f0) / delta[k]</span></span><br><span class="line">        batch_size = p0.size(<span class="number">0</span>)</span><br><span class="line">        num_points = p0.size(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># compute transforms</span></span><br><span class="line">        transf = torch.zeros(batch_size, <span class="number">6</span>, <span class="number">4</span>, <span class="number">4</span>).to(p0)</span><br><span class="line">        <span class="comment">#for b in range(p0.size(0)):</span></span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(batch_size): <span class="comment">#把这个batch中的每一个点云的transf都算出来，并且转换成6x4x4的形式</span></span><br><span class="line">            d = torch.diag(dt[b, :])  <span class="comment"># [6, 6]</span></span><br><span class="line">            D = self.exp(-d)  <span class="comment"># [6, 4, 4]</span></span><br><span class="line">            transf[b, :, :, :] = D[:, :, :]</span><br><span class="line">        transf = transf.unsqueeze(<span class="number">2</span>).contiguous()  <span class="comment"># [B, 6, 4, 4] 展开成 [B, 6, 1, 4, 4]</span></span><br><span class="line">        p = self.transform(transf, p0.unsqueeze(<span class="number">1</span>))  <span class="comment"># x [B, 1, N, 3] -&gt; [B, 6, N, 3]</span></span><br><span class="line"></span><br><span class="line">        f0 = f0.unsqueeze(-<span class="number">1</span>)  <span class="comment"># [B, K, 1]</span></span><br><span class="line">        f1 = self.encoder(p.view(-<span class="number">1</span>, num_points, <span class="number">3</span>)) <span class="comment"># 这里的num_points 是以p0（source为主的）B x N x 3 &gt; B x K</span></span><br><span class="line">        f = f1.view(batch_size, <span class="number">6</span>, -<span class="number">1</span>).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [B, K, 6]</span></span><br><span class="line">        df = f0 - f  <span class="comment"># [B, K, 6]</span></span><br><span class="line">        J = df / dt.unsqueeze(<span class="number">1</span>)  <span class="comment"># [B, K, 6]</span></span><br><span class="line">        <span class="keyword">return</span> J</span><br></pre></td></tr></table></figure></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Feature-metrics-Registration-解读&quot;&gt;&lt;a href=&quot;#Feature-metrics-Registration-解读&quot; class=&quot;headerlink&quot; title=&quot;Feature-metrics Registration 解</summary>
      
    
    
    
    <category term="Notes" scheme="http://example.com/categories/Notes/"/>
    
    
    <category term="Computer Graphics" scheme="http://example.com/tags/Computer-Graphics/"/>
    
    <category term="Computer Vision" scheme="http://example.com/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>KMP算法解读和实现</title>
    <link href="http://example.com/2022/02/07/KMP%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/02/07/KMP%E7%AE%97%E6%B3%95/</id>
    <published>2022-02-07T03:32:26.000Z</published>
    <updated>2022-03-01T14:54:10.546Z</updated>
    
    <content type="html"><![CDATA[<h2 id="KMP算法解读和实现"><a href="#KMP算法解读和实现" class="headerlink" title="KMP算法解读和实现"></a>KMP算法解读和实现</h2><p>KMP算法我记得大二学数据结构的时候遇到过，但是自己复现的时候还是不会计算next 数组导致了一些bug。最后参考b站正月大佬的视频终于学懂了，趁热打铁记录一下。</p><p>背景知识就不重复介绍了，对于KMP字符匹配，我们如果直接用brute force 的方法的话，会出现一个效率很低的问题：当匹配出错了，就会从头开始重新匹配，这样的效率非常低。因此，就引入了KMP算法。</p><p>KMP算法的特点就是用到了一个prefix table 数组，这个数组不同的人有不同的解释，我取了我最能够接受的版本：$next[i]$表示的是pattern 字符串上前$i-1$个字符最大公共前缀长度。</p><p>next数组在kmp算法中的应用主要是，当匹配出错的时候，指向source字符串的下标不会回退到最开头。举个例子，当source=”ababababaad”和pattern=”ababaa”时，当匹配到”ababa”时，source[5]和pattern[5]匹配不上，此时按照brute force的算法，会把指向source的指针指向1，重新开始，但是这样效率会比较低。在上述的匹配情况下，虽然b无法与a匹配上，但是下一轮不需要把两个指针清零重来。</p><p>用一个简短的证明来说明上述情况。假设pattern为P，source为S，针对P的指针为i，针对S的指针为j，那么有以下证明：</p><blockquote><p>ptr = next[j-1], 那么有p[0 ~ ptr-1] = p[j-ptr ~ j-1].</p><p>又因为前面的匹配是成功的，则有s[i-ptr ~ i-1] = p[j-ptr ~ j-1] </p><p>如此推断，则有p[0 ~ ptr-1]与s[i-ptr ~ i-1]匹配得上，那么接下来，直接比较p[ptr]与s[i]即可。如果两者相等，则在next[ptr]的基础上加1，得到next[i]的值。</p></blockquote><p>有了上述证明，就能比较清楚地描述next数组在KMP算法中的应用。它的作用主要是减少指针i的移动，在匹配出错的情况下，可以回退成目前pattern的一个子集而不是完全清零，从而提高了计算效率。KMP算法主体代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">strStr</span><span class="params">(String haystack, String needle)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(needle.length() == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(haystack.length() == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span>[] next = buildNext(needle);</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; haystack.length()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (haystack.charAt(i) == needle.charAt(j)) &#123;</span><br><span class="line">            i += <span class="number">1</span>;</span><br><span class="line">            j += <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span>(j &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                j = next[j - <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                i += <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(j == needle.length()) &#123;</span><br><span class="line">            <span class="keyword">return</span> i - j;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来是实现prefix table 的流程。前面已经介绍了，prefix table的意义是记录固定长度子串的最大前缀长度。举个例子，对于字符串”cabcaca”,长度为7，则next数组数值如下表所示：</p><p>cabcaca</p><p>0123456</p><p>0001212</p><p>计算next数组的算法如下：</p><blockquote><p>首先对于$next[0]$要先赋值成0. 假设pattern为p.</p><p>设置两个指针i和len，i指向的是当前要求next数组的下标，len表示的是其比较前缀的位置。</p><p>如果p[len] == p[i]，说明当前匹配成功，那么可以给next[i]赋值成len+1。做完以后len+1，i+1. 举例：</p><p>​    <em>当前len=0，i=3，p=“abba”，匹配成功，此时p的最长前缀的长度是1。</em></p><p>如果p[len] != p[i], 说明匹配失败了，但是这个时候也不是完全清零数组，而是像kmp算法主要部分一样回退到前面，看看前面有没有可以给目前的尾缀匹配的内容。举例：</p><p>​    当p=”ebebee”的时候，匹配到i=5的时候匹配出错，但是此时p[0 ~ 2]和p[2 ~ 4]是相等的，两者用m和n表示。如果m切片后的最开头与n切片后的最结尾相同，我们就可以开始重新匹配，即比较切片后m后面的第一个和n切片后的第一个是否相同，如果相同，则是子串匹配成功了。比如上面的例子，因为len=3，取len = next[len -  1]，下次我们只需要比较p[len]与p[i]的值，如果相等则next[i] = len+1.</p></blockquote><p>next数组实现算法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">int</span>[] buildNext(String needle) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] next = <span class="keyword">new</span> <span class="keyword">int</span>[needle.length()];</span><br><span class="line">        <span class="keyword">char</span>[] str = needle.toCharArray();</span><br><span class="line">        next[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(i &lt; needle.length()) &#123;</span><br><span class="line">            <span class="keyword">if</span>(str[i] == str[len]) &#123;</span><br><span class="line">                len += <span class="number">1</span>;</span><br><span class="line">                next[i] = len;</span><br><span class="line">                i += <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span>(len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    len = next[len - <span class="number">1</span>];</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    next[i] = <span class="number">0</span>;</span><br><span class="line">                    i += <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里复现了上面的算法阐述，多的是处理了数组下标溢出的问题。可以看到，next[len-1]在len=0的时候是取不到的，这也说明了当前的回退已经回退到最开头了，说明确实没有可以与现在i所在位置匹配的字符。此时应该让i++，开始下一轮循环。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;KMP算法解读和实现&quot;&gt;&lt;a href=&quot;#KMP算法解读和实现&quot; class=&quot;headerlink&quot; title=&quot;KMP算法解读和实现&quot;&gt;&lt;/a&gt;KMP算法解读和实现&lt;/h2&gt;&lt;p&gt;KMP算法我记得大二学数据结构的时候遇到过，但是自己复现的时候还是不会计算n</summary>
      
    
    
    
    <category term="Notes" scheme="http://example.com/categories/Notes/"/>
    
    
    <category term="LeetCode" scheme="http://example.com/tags/LeetCode/"/>
    
    <category term="Algorithm" scheme="http://example.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Correspondence-Free Point Cloud Registration  阅读笔记</title>
    <link href="http://example.com/2022/01/03/Correspondence-Free/"/>
    <id>http://example.com/2022/01/03/Correspondence-Free/</id>
    <published>2022-01-03T03:32:26.000Z</published>
    <updated>2022-03-12T16:25:57.664Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Correspondence-Free-Point-Cloud-Registration-with-SO-3-Equivariant-Implicit-Shape-Representations-2021"><a href="#Correspondence-Free-Point-Cloud-Registration-with-SO-3-Equivariant-Implicit-Shape-Representations-2021" class="headerlink" title="Correspondence-Free Point Cloud Registration with SO(3)-Equivariant Implicit Shape Representations(2021)"></a>Correspondence-Free Point Cloud Registration with SO(3)-Equivariant Implicit Shape Representations(2021)</h1><p>这篇文章比较新，我在网上也没找到比较好的参考，更惨的是他们的github repo page居然是空的。没有任何可考的其他资料，我只能简单记录一下我对他们思路的理解。</p><h2 id="1-Preliminaries"><a href="#1-Preliminaries" class="headerlink" title="1. Preliminaries"></a>1. Preliminaries</h2><p><strong>Equivariance</strong>: 一种不变性，平移或者旋转以后对函数的输出结果不造成影响。(for efficient learning and generalization)。 作者提出，使用equivariant neural network可以让Point Cloud的rotation 值通过network以后保持不变从而方便做feature alignment （第二部分再细讲）</p><p>比如，对于一个2D的图像，对它施加一个translation，然后通过neural network 后的结果，与直接将这个2D图像放入neural network 的结果再加上此translation是一样的。此前的Point Cloud Registration models都对rotation不是equivariant，本文的作者采用了Vector Neurons 使得学习点云特征的时候可以保证rotation上的equivariant.</p><p><strong>Vector Neurons</strong>: augment the scalar feature in each feature dimension to a vector in $\R^3$ and redesign the linear, nonlinear, pooling, and normalization layers accordingly.</p><p>在VNN里面，feature matrix 的维度是$N\times C \times 3$, $N$为Point Cloud中的点数量，$C$为feature 的原始维度。作者为VNN设计了新的linear层和non-linear层，从而让$SO(3)$ 是equivariant的.</p><h2 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2. Methodology"></a>2. Methodology</h2><h3 id="2-1-Global-feature-extractor"><a href="#2-1-Global-feature-extractor" class="headerlink" title="2.1 Global feature extractor"></a>2.1 Global feature extractor</h3><p>采用了前人的PointNet做feature extractor，但改进成了Vector Neuron的版本。然后这里进行了一个推导，来证明原始Point cloud $P$ 的feature $Q$，与$P$做了一系列permutation变换（即为$M\in \R^{N\times N}$）以及rotation（$R\in SO(3)$) 后的点云$P’$所提取出来的特征$Q’$有如下关系：</p><script type="math/tex; mode=display">Q'=QR.</script><p> 这个证明很好理解，主要是要明白这个feature extractor $f$ 对rotation是equivariant的，所以存在$f(MPR)=f(MP)R$. 因为$M$对network的输出结果没有影响所以可以直接去掉，从而推导出上面的公式。这个公式很重要，后面会有用到。</p><p>因为是Vector Neuron版本的feature extractor，输入的pioint cloud 维度也要做一些改变。因此作者在这里用了DGCNN的edge-convolution layer，将维度为$N\times 3$的点云集合初始化成了$N\times C\times 3$维度的特征。特征自然是需要从周边的点云来生成，因此这里也是用了KNN的方法。并且作者认为这样做可以减轻network对点云的密度敏感。</p><h3 id="2-2-Deep-implict-representation-learning"><a href="#2-2-Deep-implict-representation-learning" class="headerlink" title="2.2 Deep implict representation learning"></a>2.2 Deep implict representation learning</h3><p>作者认为在实际情况下，point cloud的对齐是存在noise的。针对这种情况，作者提出了一种encoder-decoder机制，为的就是能够处理implict的时候的对齐问题。下面展示的是encoder和decoder的输入输出以及他们的效果。大致思想就是对于每一个point cloud 都有一些检查点，来计算概率，通过这个值就可以修正我们的网络，从而正确判定一些implict的点是否在这个点云里面。</p><ul><li>encoder: 输入点云$P\in \R^{N\times 3}$， 输出点云的encoded shape feature $Q.$​​​ 这里的encoder自然是遵循前文的SO(3)-equivariant</li><li>decoder: 输入feature $Q$以及查询的position $p$​（这些查询点是通过Occupancy Network生成的值），输出该点在点云内的预测occupancy value值$v$.</li></ul><p>算法流程大概如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- for P in dataset:</span><br><span class="line">- 用Occupancy Network取样sample points S作为queried position</span><br><span class="line">  - Q=encoder(P), P为点云，Q为shape feature</span><br><span class="line">  - for p in S:</span><br><span class="line">    - calculate occupancy value</span><br><span class="line">  - calculate occ_loss, backward</span><br></pre></td></tr></table></figure><h3 id="2-3-Point-cloud-registration"><a href="#2-3-Point-cloud-registration" class="headerlink" title="2.3 Point cloud registration"></a>2.3 Point cloud registration</h3><p>前面已经推导了$Q’=QR$, 作者这里把$Q$和$Q’$都看成是两个伪点云，并且each row of them is <em>automatically matched</em>。 接着用SVD求解出R就可以了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Correspondence-Free-Point-Cloud-Registration-with-SO-3-Equivariant-Implicit-Shape-Representations-2021&quot;&gt;&lt;a href=&quot;#Correspondence-Fre</summary>
      
    
    
    
    <category term="Literature Review" scheme="http://example.com/categories/Literature-Review/"/>
    
    
    <category term="Computer Graphics" scheme="http://example.com/tags/Computer-Graphics/"/>
    
  </entry>
  
  <entry>
    <title>Torch, CUDA版本匹配以及实验室服务器配置</title>
    <link href="http://example.com/2021/12/26/Torch,-CUDA%E7%89%88%E6%9C%AC%E5%8C%B9%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2021/12/26/Torch,-CUDA%E7%89%88%E6%9C%AC%E5%8C%B9%E9%85%8D%E4%BB%A5%E5%8F%8A%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/</id>
    <published>2021-12-26T03:32:26.000Z</published>
    <updated>2022-03-01T14:54:31.620Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Problem-Restate"><a href="#Problem-Restate" class="headerlink" title="Problem Restate"></a>Problem Restate</h3><p>最近在学DCP，官方的代码是基于Pytorch实现的，我也算是搞清楚了之前说的torch、cuda以及显卡版本对齐的问题，因此在这里记录一下。此外，我用conda配置了执行pytorch的环境，适用于我们组的服务器。参数也记录在本文中，适用于后期复用。</p><h3 id="NVIDIA显卡和CUDA"><a href="#NVIDIA显卡和CUDA" class="headerlink" title="NVIDIA显卡和CUDA"></a>NVIDIA显卡和CUDA</h3><p>显卡就是我们服务器用的GPU，用于做深度学习各种张量的运算；CUDA是用于Nvidia的计算框架，对GPU进行加速。在linux命令行，可以用<code>nvcc -V</code> 或者<code>nvidia-smi</code>进行查看CUDA版本。我们实验室的显卡版本是GeForce RTX 3090 （老板大气），官方的算力是8.6（并非挖矿算力）。Nvidia的显卡算力可以在<a href="https://developer.nvidia.com/cuda-gpus#collapseOne">https://developer.nvidia.com/cuda-gpus#collapseOne</a> 找。</p><p>最开始我跑深度学习框架的时候基本上不怎么在乎版本对齐的问题，也都马马虎虎蒙混过关了，但这用组里的新服务器的时候得自己从头配起，就遇到了一些问题。最经典的报错就是如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.</span><br><span class="line">The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.</span><br><span class="line">If you want to use the GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/</span><br></pre></td></tr></table></figure><p>没有主要到算力问题的我一开始根本就没觉得sm_86是算力的意思。这个报错原因是这样的：显卡的算力与当前使用的pytorch依赖的cuda版本不一样，因为当前依赖的cuda只能支持算力为3.7~7.5的显卡。要升级cuda的配置。简单地说就是显卡的cuda版本与pytorch的cuda版本不一样。遇到这个问题的时候有多种解决方案，本质就是要对齐两个cuda的版本。我这里的解决方案是安装与显卡一样cuda版本的pytorch。【注意：cuda并不支持向下兼容】</p><h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h4><p>我用<code>cat /usr/local/bin/cuda</code> 查看版本后发现是10.1，而我之前安装的pytorch版本对应的cuda版本并不是10.1. 因此我用pip3 uninstall 了之前的torch和torchvision，准备用官网给的命令安装合适版本的pytorch。可以去 www.pytorch.org 上找自己电脑/ 服务器对应的命令。 但是问题又出现了，应该是校园网的锅，完全连不上pytorch的官网，每次pip3 install都以SSL connection fail而结束。</p><p>考虑到pip3安装用的就是wlh文件，然后解压编译，我先在自己的电脑上下载了这两个文件（在找版本的时候对应我在前面说的要点找合适版本的wlh文件）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch-1.8.0+cu111-cp37-cp37m-linux_x86_64.whl</span><br><span class="line">torchvision-0.9.0+cu111-cp37-cp37m-linux_x86_64.whl</span><br></pre></td></tr></table></figure><p>可以在 <a href="https://download.pytorch.org/whl/torch_stable.html">https://download.pytorch.org/whl/torch_stable.html</a> 找各个版本的.whl文件，并下载。然后在terminal里面用scp命令将它俩上传到了服务器。可以注意到我这里安装的torch版本对应的cuda是11.1，这样显卡和上层应用的cuda版本也算是门当户对了。</p><p>最后就是在conda里面activate环境，用pip把这前面说的whl文件安装好，就可以使用了。可以用下面的python代码自检一下安装是否到位。如果下面几句都顺利执行，那么就说明你的环境已经配好了。如果最后一句不报错，但是怎么都运行不完，那就说明你的torch版本依旧有问题，建议更新到最新。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch <span class="comment"># 是否下载torch</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.cuda.is_available() <span class="comment">#查看cuda是否可用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.Tensor([<span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = a.cuda() <span class="comment">#查看是否可以转换，也就是gpu是否起作用了</span></span><br></pre></td></tr></table></figure><p>另外我在查找解决方案的时候看到了一篇关于cuda版本与显卡的介绍性文章，可以参考一下：<a href="https://blog.csdn.net/Fzc_Ztt/article/details/119974995">https://blog.csdn.net/Fzc_Ztt/article/details/119974995</a> </p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;Problem-Restate&quot;&gt;&lt;a href=&quot;#Problem-Restate&quot; class=&quot;headerlink&quot; title=&quot;Problem Restate&quot;&gt;&lt;/a&gt;Problem Restate&lt;/h3&gt;&lt;p&gt;最近在学DCP，官方的代码是基于Py</summary>
      
    
    
    
    <category term="Solutions" scheme="http://example.com/categories/Solutions/"/>
    
    
    <category term="Linux" scheme="http://example.com/tags/Linux/"/>
    
    <category term="PyTorch" scheme="http://example.com/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Deep Closes Point 阅读笔记</title>
    <link href="http://example.com/2021/12/21/Point-Cloud-Registration-md/"/>
    <id>http://example.com/2021/12/21/Point-Cloud-Registration-md/</id>
    <published>2021-12-21T03:32:26.000Z</published>
    <updated>2022-03-06T08:46:13.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Deep-Closest-Point-Learning-Representations-for-Point-Cloud-Registration-May-2019"><a href="#Deep-Closest-Point-Learning-Representations-for-Point-Cloud-Registration-May-2019" class="headerlink" title="Deep Closest Point: Learning Representations for Point Cloud Registration (May, 2019)"></a>Deep Closest Point: Learning Representations for Point Cloud Registration (May, 2019)</h1><h2 id="1-Problem-restate"><a href="#1-Problem-restate" class="headerlink" title="1. Problem restate"></a>1. Problem restate</h2><p>Given exact correspondences, singular value decomposition yields the globally optimal alignment. However when matching two point cloud sets, the correspondence of them are unkown. The most popular algorithm Iterative Closest Point (ICP) alternates between estimating the rigid motion based on a fixed correspondence estimate and updating the corre- spondences to their closest matches. ICP might act poorly due to its trend to local optima. Therefore, the author proposed a deep learning method DCP to improve the performance of ICP.</p><h2 id="2-Related-works"><a href="#2-Related-works" class="headerlink" title="2. Related works"></a>2. Related works</h2><p>DGCNN &amp; PointNet are two Deep Learning algorithms to extract features in 3D mesh points. PointNet manipulate points independely, DGCNN will dynamically update the graph and features. Using these two architectures we can obtain more information on subareas.</p><p>Seq2seq is importtant NLP researches. It often involves predicting discrete tokens corresponding to positions in the input sequence. The author convert the point registration problem into token matching.</p><p>Transformer：<a href="https://codefmeister.github.io/p/图解transformer/">https://codefmeister.github.io/p/图解transformer/</a></p><h2 id="3-DCP-architecture"><a href="#3-DCP-architecture" class="headerlink" title="3. DCP architecture"></a>3. DCP architecture</h2><p>Deep Closest Point 分为三个部分：（输入为两个点云X，Y）</p><ol><li>点云特征提取网络，得到点云特征</li><li>基于注意力的点云匹配预测，得到点云之间的预测matching</li><li>可微的SVD模块，得到点云XY之间的刚性变换</li></ol><h3 id="3-1-Initial-Features"><a href="#3-1-Initial-Features" class="headerlink" title="3.1 Initial Features"></a>3.1 Initial Features</h3><p>In the first stage, embeds the input point clous into a common space. to find an embedding that quotients out rigid motion while remaining sensitive to relevant features for rigid matching. Tried two embedding modules: PointNet and DGCNN.(特征提取器)</p><p><strong>PointNet（抽取全局特征）， DGCNN（结合局部特征和全局特征）</strong>。DGRCNN相比于PointNet额外编码了局部几何信息 (PointNet features do not incorporate local neighborhood information)，作者认为这将有助于配准精度。因此在整个架构里采用了DGCNN进行embedding。</p><p>值得注意的是，对于$X、Y$两个点云的匹配，我们需要的是每个点的特征（per-point feature）因此是用的聚合函数前面一层生成每个点的表达$F_X$和$F_Y$​.</p><h3 id="3-2-Attention"><a href="#3-2-Attention" class="headerlink" title="3.2 Attention"></a>3.2 Attention</h3><p>论文提出每个点云的特征不应当独立的提取，而是联合两个输入点云提取，使得最终得到的两个特征适用于特定的任务（即配准，task specific）将注意力输出作为残差项修正原来的特征. The attention model learns a function that could revise previous features <script type="math/tex">F_X, F_Y</script>​​.</p><p>修正后的$\Phi_X$​将点与feature之间的连接加上了$Y$​的结构 (knowledgeable about the structure of $Y$​​)也就是$Y$中各点的输入顺序。对于$\Phi_Y$ 也是对称的用途。</p><p>We can get a matching function (soft pointer):</p><script type="math/tex; mode=display">m(x_i, Y)=softmax(\Phi_Y\Phi^T_{x_i})</script><p>可将其视为点x_i到Y中各个点的软指针(概率向量)，a <em>soft pointer</em> from each xi into the elements of Y. 如果是用DL- based algorithms to generate this function m, we don’t need to iteratively revise the matching pairs.</p><p><strong>Transformer</strong></p><p><code>self-attention</code>层可以帮助我们在对某个特定的词进行编码的时候同时关注到句子中其他位置单词的影响。</p><h3 id="3-3-SVD-module"><a href="#3-3-SVD-module" class="headerlink" title="3.3 SVD module"></a>3.3 SVD module</h3><p>We use the soft pointers to generate a matching averaged point in Y for each point in X.(这一步就和求期望值E(X)差不多) R and t (transition matrix) are extracted using SVD based on the pairing points in X and Y. 得到了X和Y的点云匹配（correspondence关系）以后，使用SVD分解得到从X到Y的变换矩阵。</p><p>To backpropagate gradients through the networks, we need to differentiate the SVD.</p><h3 id="3-4-Loss函数"><a href="#3-4-Loss函数" class="headerlink" title="3.4 Loss函数"></a>3.4 Loss函数</h3><p>Combined, the modules above map from a pair of point clouds X and Y to a rigid motion [RXY,tXY] that aligns them to each other. 直接使用变换矩阵与真值之间的偏差作为损失。</p><h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h2><p>两个版本V1、V2：无注意力机制的为v1.</p><p>参考：</p><p><a href="https://blog.csdn.net/phy12321/article/details/107345530?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link">https://blog.csdn.net/phy12321/article/details/107345530?spm=1001.2101.3001.6650.5&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.no_search_link</a></p><p>代码解读：<a href="https://blog.csdn.net/weixin_43977640/article/details/111747196">https://blog.csdn.net/weixin_43977640/article/details/111747196</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Deep-Closest-Point-Learning-Representations-for-Point-Cloud-Registration-May-2019&quot;&gt;&lt;a href=&quot;#Deep-Closest-Point-Learning-Representat</summary>
      
    
    
    
    <category term="Literature Review" scheme="http://example.com/categories/Literature-Review/"/>
    
    
    <category term="Computer Graphics" scheme="http://example.com/tags/Computer-Graphics/"/>
    
  </entry>
  
  <entry>
    <title>Deep Global Registration 阅读笔记</title>
    <link href="http://example.com/2021/12/15/Deep-Global-Registration/"/>
    <id>http://example.com/2021/12/15/Deep-Global-Registration/</id>
    <published>2021-12-15T03:32:26.000Z</published>
    <updated>2022-04-04T16:27:52.757Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Deep-Global-Registration-2020-阅读笔记"><a href="#Deep-Global-Registration-2020-阅读笔记" class="headerlink" title="Deep Global Registration(2020) 阅读笔记"></a>Deep Global Registration(2020) 阅读笔记</h1><h2 id="2-DGR-architecture"><a href="#2-DGR-architecture" class="headerlink" title="2. DGR architecture"></a>2. DGR architecture</h2><h3 id="2-1-Feature-extraction"><a href="#2-1-Feature-extraction" class="headerlink" title="2.1 Feature extraction"></a>2.1 Feature extraction</h3><p>We use Fully Convolutional Geometric Features (FCGF), which have recently been shown to be both discriminative and fast.</p><h3 id="2-2-Correspondence-confidence-prediction"><a href="#2-2-Correspondence-confidence-prediction" class="headerlink" title="2.2 Correspondence confidence prediction"></a>2.2 Correspondence confidence prediction</h3><p>we use the <strong>nearest neighbor</strong> in the feature space to generate a set of putative correspondences $M$.(确定性算法)</p><p>To filter out noisy correspondences: we propose to learn this filtering process through a convolutional network that learns to analyze the underlying geometric structure of the correspondence set. </p><h3 id="2-4-一种微调R和t的方法"><a href="#2-4-一种微调R和t的方法" class="headerlink" title="2.4 一种微调R和t的方法"></a>2.4 一种微调R和t的方法</h3><p>使用6D的那个对应关系即x和y的对应关系，作者使用6D向量表示旋转矩阵。这里的b1、b2、b3均是三维向量，$b1=N(a1)$，$b2=N(a2-(b1*a2)b1)$，$b3=b1×b2$.<br>这里的$N$就是L2 norm的意思，通过这样的定义就可以使a1、a2与我们真正需要的R和t之间进行转换。</p><p>大场景 -&gt; 重叠度慢慢降低 （90%）<br><strong><em>数据集对于重叠的问题</em></strong><br>部分数据  – 全局数据的使用<br>数据集 - 重叠度大的<br>无重叠 -&gt; fmr ++ dgr – &gt;重叠度问题</p><p>多尺度特征</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Deep-Global-Registration-2020-阅读笔记&quot;&gt;&lt;a href=&quot;#Deep-Global-Registration-2020-阅读笔记&quot; class=&quot;headerlink&quot; title=&quot;Deep Global Registration</summary>
      
    
    
    
    <category term="Literature Review" scheme="http://example.com/categories/Literature-Review/"/>
    
    
    <category term="Computer Graphics" scheme="http://example.com/tags/Computer-Graphics/"/>
    
  </entry>
  
  <entry>
    <title>使用CMake 编译深度学习模块出现Fatal Error</title>
    <link href="http://example.com/2021/11/02/%E4%BD%BF%E7%94%A8CMake-%E7%BC%96%E8%AF%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9D%97%E5%87%BA%E7%8E%B0Fatal-Error/"/>
    <id>http://example.com/2021/11/02/%E4%BD%BF%E7%94%A8CMake-%E7%BC%96%E8%AF%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9D%97%E5%87%BA%E7%8E%B0Fatal-Error/</id>
    <published>2021-11-02T05:03:12.000Z</published>
    <updated>2021-12-28T06:42:42.291Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用CMake-编译深度学习模块出现Fatal-Error"><a href="#使用CMake-编译深度学习模块出现Fatal-Error" class="headerlink" title="使用CMake 编译深度学习模块出现Fatal Error"></a>使用CMake 编译深度学习模块出现Fatal Error</h2><h3 id="Problem-restate"><a href="#Problem-restate" class="headerlink" title="Problem restate"></a>Problem restate</h3><p>最近在学PoseCNN，里面有一个HoughVoting Layer，是投票层，通过投票决定反馈内容。我使用了UMich的代码，里面HoughVoting部分他们使用cpp写的。其中，它调用了以下内容：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;eigen3/Eigen/Dense&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;opencv2/opencv.hpp&quot;</span></span></span><br></pre></td></tr></table></figure><p>一开始我是摸不着头脑，不知道怎么用python执行cpp，在知道了以后又报了很多错。现在弄出来了，做个记载。</p><h3 id="PyTorch的C-extension"><a href="#PyTorch的C-extension" class="headerlink" title="PyTorch的C++ extension"></a>PyTorch的C++ extension</h3><p>用C++的拓展可以实现一些PyTorch自己没有的内容。pytorch的C++ extension和python的c/c++ extension其实原理差不多，本质上都是为了扩展各自的功能。流程就是，先用C++写出自己扩展的模块，接着是写<code>setup.py</code>脚本，用python的setuptools来编译C++代码（其实就是把编译过程自动化）编译好以后就可以用自己的代码调用写的模块了！</p><p>详细的写extension的部分可以参考这一篇<a href="https://zhuanlan.zhihu.com/p/100459760，我现在只是为了调用，所以只要能set">https://zhuanlan.zhihu.com/p/100459760，我现在只是为了调用，所以只要能set</a> up就行。</p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>直接先去lib/HoughVoting 下，执行<code>setup.py</code>脚本。命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python setup.py install</span><br></pre></td></tr></table></figure><p>这时候报了下面的错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">houghvoting.cc:10:10: fatal error: /usr/include/opencv2: No such file or directory</span><br><span class="line">fatal error: Eigen/Core: No such file or directory</span><br></pre></td></tr></table></figure><p>我先前已经sudo安装了这些包，还是有这样的问题，于是考虑是不是位置放错了。于是到安装的位置/usr/include 下去查看，发现下载的opencv放在了opencv4/opencv2里面。这种情况下， 需要把opencv2挪出来到/usr/include下。</p><p>类似的，Eigen也有这样的问题。这是因为 eigen 库默认安装在了 /usr/include/eigen3/Eigen 路径下，可以cp，也可以使用下面命令映射到 /usr/include 路径下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /usr/include/eigen3/Eigen /usr/include/Eigen</span><br></pre></td></tr></table></figure><p>再回去编译，就没有报错，成功！回到python，就可以直接用import引用了。</p><p>之后，在跑Deep-IM的时候又出现了下面这样一个问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">-gencode=arch=compute_80,code=sm_80 -std=c++14</span><br><span class="line">nvcc fatal : Unsupported gpu architecture &#x27;compute_80&#x27;</span><br></pre></td></tr></table></figure><p>谷歌了很久以后，出现问题的原因都指向了一个理由，就是我的cuda版本没有和安装的torch以及torchvision同步。我们服务器的cuda是<code>10.1</code>，因此下的torch 和torchvision都要是匹配10.1版本的。这个可以在官网上查到。因此我现在的配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html</span><br></pre></td></tr></table></figure><p>这个问题让我意识到我之前都没有太关注版本的问题，但其实这会对执行代码时的算力造成很大的影响。还是要多加练习。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;使用CMake-编译深度学习模块出现Fatal-Error&quot;&gt;&lt;a href=&quot;#使用CMake-编译深度学习模块出现Fatal-Error&quot; class=&quot;headerlink&quot; title=&quot;使用CMake 编译深度学习模块出现Fatal Error&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="Solutions" scheme="http://example.com/categories/Solutions/"/>
    
    
    <category term="Linux" scheme="http://example.com/tags/Linux/"/>
    
    <category term="CMake" scheme="http://example.com/tags/CMake/"/>
    
  </entry>
  
  <entry>
    <title>MacOS下使用XQuartz 连接Linux服务器的图形化界面</title>
    <link href="http://example.com/2021/11/01/MacOS%E4%B8%8B%E4%BD%BF%E7%94%A8XQuartz-%E8%BF%9E%E6%8E%A5Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2/"/>
    <id>http://example.com/2021/11/01/MacOS%E4%B8%8B%E4%BD%BF%E7%94%A8XQuartz-%E8%BF%9E%E6%8E%A5Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2/</id>
    <published>2021-11-01T03:32:26.000Z</published>
    <updated>2021-12-26T15:54:10.399Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Mac环境下使用XQuartz-连接Linux服务器的图形化界面"><a href="#Mac环境下使用XQuartz-连接Linux服务器的图形化界面" class="headerlink" title="Mac环境下使用XQuartz 连接Linux服务器的图形化界面"></a>Mac环境下使用XQuartz 连接Linux服务器的图形化界面</h2><h3 id="Problem-Restate"><a href="#Problem-Restate" class="headerlink" title="Problem Restate"></a>Problem Restate</h3><p>一般Mac连接服务器的时候，都很方便，因为在Terminal里面可以直接输入<code>ssh name@IP</code>就能调用服务器的命令行。但我现在用的这个服务器有时候需要连接校园网，校园网登录只提供了浏览器那里输入用户和密码的接口。在网上查询到解决方案：使用XQuartz进行连接，就可以调用。</p><h3 id="X11-介绍"><a href="#X11-介绍" class="headerlink" title="X11 介绍"></a>X11 介绍</h3><p>XQuartz（工具）+ X11 Forwarding技术就可以完成本地对Linux 图形化界面的获取，原理就是X协议中，X Server可以获取用户鼠标键盘等动作，反馈给X Client，Client就可以反馈请求。</p><h3 id="解决步骤"><a href="#解决步骤" class="headerlink" title="解决步骤"></a>解决步骤</h3><p>去官网[<a href="http://Xquartz.org">http://Xquartz.org</a>] 下载XQuartz，或者在Terminal使用<code>brew install</code> 下载。</p><p>启动了XQuartz后，设置Display环境变量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export DISPLAY=:0</span><br></pre></td></tr></table></figure><p>分别配置Linux和本机上的配置文件，设置X11连接参数：</p><p>Linux服务器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ssh/sshd_config</span><br><span class="line">#进去以后修改以下两个参数：</span><br><span class="line">X11Forwarding yes</span><br><span class="line">X11DisplayOffset 10</span><br></pre></td></tr></table></figure><p>Mac本机：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ssh/ssh_config</span><br><span class="line">ForwardAgent yes</span><br><span class="line">ForwardX11 yes</span><br><span class="line">ForwardX11Trusted yes</span><br><span class="line">XAuthLocation /opt/X11/bin/xauth</span><br></pre></td></tr></table></figure><p><code>ssh_config</code>是针对客户端的配置文件，<code>sshd_config</code>则是针对服务端的配置文件。两个配置文件都允许你通过设置不同的选项来改变客户端程序的运行方式。</p><p>这时候，就可以通过XQuartz连接远程服务器了（ssh命令）。注意要在XQuartz的Preferences里面找到Security，选中Allow connections from network clients.如果这里出现了X11 forwarding request failed on channel 0错误，则是因为没安装xauth引起的，安装了就能解决。</p><p>可以先测试一下自己是否能使用X11协议，方法就是调用X11自带的xclock（在命令行里直接输入即可）如果跳转出了一个桌面时钟，说明协议成功。接下来就可以使用命令行调用浏览器了！我们服务器里已经下好了firefox，我是直接在命令行里调用了<code>firefox</code>，然后就弹出了如下所示的界面：</p><p><img src="/Users/liqilin/Desktop/本科/myBlog/fig/Snip20211101_5.png" alt="Snip20211101_5"></p><p>可以发现，这个界面是在XQuartz的支持下弹出的，也就是说明我们使用的是X11协议，访问了Linux的图形化界面。用起来还是蛮卡的，现在我只用它来连接校园网。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Mac环境下使用XQuartz-连接Linux服务器的图形化界面&quot;&gt;&lt;a href=&quot;#Mac环境下使用XQuartz-连接Linux服务器的图形化界面&quot; class=&quot;headerlink&quot; title=&quot;Mac环境下使用XQuartz 连接Linux服务器的图</summary>
      
    
    
    
    <category term="Solutions" scheme="http://example.com/categories/Solutions/"/>
    
    
    <category term="Linux" scheme="http://example.com/tags/Linux/"/>
    
    <category term="MacOS" scheme="http://example.com/tags/MacOS/"/>
    
  </entry>
  
  <entry>
    <title>Eye Gaze Estimation</title>
    <link href="http://example.com/2021/01/28/Eye-Gaze-Estimation-md/"/>
    <id>http://example.com/2021/01/28/Eye-Gaze-Estimation-md/</id>
    <published>2021-01-28T03:32:26.000Z</published>
    <updated>2021-12-26T15:54:32.929Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Gaze-Estimation"><a href="#Gaze-Estimation" class="headerlink" title="Gaze Estimation"></a>Gaze Estimation</h1><h3 id="1-Project-Overview"><a href="#1-Project-Overview" class="headerlink" title="1. Project Overview"></a>1. Project Overview</h3><p>This is a task to predict <strong>where</strong> a person is looking at given the person’s full face. </p><p>Two directions of task:</p><ul><li>3-D gaze vector estimation is to predict the gaze vector, which is usually used in the automotive safety.</li><li>2-D gaze position estimation is to predict the horizontal and vertical coordinates on a 2-D screen, which allows utilizing gaze point to control a cursor for human-machine interaction.</li></ul><p>usability: track the eye movement, provide detailed insights into users’ attention.</p><p>challenges: (a) low sensor quality or unknown/challenging environments, and (b) large variations in eye region appearance.</p><h3 id="2-Dataset-Info"><a href="#2-Dataset-Info" class="headerlink" title="2. Dataset Info"></a>2. Dataset Info</h3><ol><li>The MPIIGaze Dataset (full-face gaze estimation)</li></ol><p><a href="https://www.kaggle.com/c/mp18-eye-gaze-estimation/data">https://www.kaggle.com/c/mp18-eye-gaze-estimation/data</a>  unavailable due to authentication</p><p><a href="https://github.com/swook/faze_preprocess">https://github.com/swook/faze_preprocess</a> this is ok to download</p><p>illumination, variation in record time, </p><ol><li>The Gaze-in-Wild Dataset</li></ol><p>Doing several activities, and capture their eye movement during the activities.</p><ol><li>Multi-view Gaze Dataset</li></ol><p><a href="https://www.ut-vision.org/datasets/">https://www.ut-vision.org/datasets/</a></p><p>without the need for person-specific calibra- tion settings</p><h3 id="3-General-Idea"><a href="#3-General-Idea" class="headerlink" title="3. General Idea"></a>3. General Idea</h3><ul><li>model-based:  use 3D eyeball models and estimate the gaze direction using geometric eye features</li><li>Appearance-based<ul><li>learn generic gaze estimators from large amounts of person, and head pose-independent training data.</li></ul></li></ul><h3 id="4-Literature-Review"><a href="#4-Literature-Review" class="headerlink" title="4. Literature Review"></a>4. Literature Review</h3><p>[1] Appearance-Based Gaze Estimation in the Wild </p><ul><li><p>First detect the user’s face in the image</p><ul><li>We assume a single face in the images and take the largest bounding box if the detector returns multiple face proposals. We discard all images in which the detector fails to find any face, which happened in about 5% of all cases.</li><li>definition of yaw, roll and pitch:</li><li><img src="/Users/liqilin/Library/Application Support/typora-user-images/image-20210201173745462.png" alt="image-20210201173745462" style="zoom:33%;"></li></ul><p><img src="https://www.fieldtriptoolbox.org/assets/img/faq/how_are_the_different_head_and_mri_coordinate_systems_defined/coordinatesystem_neuromag.png" alt="How are the different head and MRI coordinate systems defined? - FieldTrip  toolbox" style="zoom:33%;"></p></li></ul><ul><li><p>Fit a generic 3D facial shape model and normalize</p><ul><li>to crop and warp the head pose and eye images to the normalised training space</li><li><p>normalise the image and head pose space into a polar-coordinate angle space\</p><blockquote><p>Normalization is to cope with the rotation and extension caused by the camera. the normalisation is done by scaling and rotating the camera so that: 1) the camera looks at the midpoint of the eye corners from a fixed distance d, and 2) x axes of the head coordinate system and camera coordinate system become parallel.</p></blockquote></li></ul></li><li><p>CNN</p><ul><li><p>to learn the mapping from the head poses and eye images to gaze directions in the camera coordinate system</p></li><li><p>use of  <strong>multimodal</strong> CNN architecture. [2]</p></li><li><p>loss function: $g - upper{g}$</p></li></ul></li></ul><p>[2] Appearance-Based Gaze Estimation via Evaluation-Guided Asymmetric Regression</p><ul><li><p>3D gaze estimation via regression</p></li><li><p>Asymmetric Regression Network</p><ul><li>it is designed to be able to optimize the two eyes in an asymmetric way</li><li>structure:<ul><li>the first two streams to extract a 500D deep features from each eye independently, and the last two streams to produce a joint 500D feature in the end</li><li>input the head pose vector (3D for each eye) before the final regression</li><li>Base-CNN: similar to AlexNet</li></ul></li><li>loss function: weighted angular error<ul><li>The weights λl and λr determine whether the accuracy of the left or the right eye should be considered more important</li><li><img src="/Users/liqilin/Library/Application Support/typora-user-images/image-20210329103826104.png" alt="image-20210329103826104" style="zoom:33%;"></li></ul></li></ul></li></ul><p>  <img src="/Users/liqilin/Library/Application Support/typora-user-images/image-20210329102428166.png" alt="image-20210329102428166" style="zoom:33%;"></p><ul><li><p>Evaluation Network</p><ul><li>the evaluation network is trained to predict the probability of the left/right eye image being more efficient in gaze estimation.</li></ul></li></ul><h3 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h3><p>[1] Appearance-Based Gaze Estimation in the Wild  <a href="https://perceptual.mpi-inf.mpg.de/files/2015/04/zhang_CVPR15.pdf">https://perceptual.mpi-inf.mpg.de/files/2015/04/zhang_CVPR15.pdf</a>)</p><p>[2] Multimodal Convolutional Neural Networks for Matching Image and Sentence: <a href="https://openaccess.thecvf.com/content_iccv_2015/papers/Ma_Multimodal_Convolutional_Neural_ICCV_2015_paper.pdf">https://openaccess.thecvf.com/content_iccv_2015/papers/Ma_Multimodal_Convolutional_Neural_ICCV_2015_paper.pdf</a></p><p>[3] <a href="https://www.kaggle.com/kmader/process-mpii-dataset">https://www.kaggle.com/kmader/process-mpii-dataset</a> data processing</p><p>[4] Few-Shot Adaptive Gaze Estimation <a href="https://arxiv.org/pdf/1905.01941v2.pdf">https://arxiv.org/pdf/1905.01941v2.pdf</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Gaze-Estimation&quot;&gt;&lt;a href=&quot;#Gaze-Estimation&quot; class=&quot;headerlink&quot; title=&quot;Gaze Estimation&quot;&gt;&lt;/a&gt;Gaze Estimation&lt;/h1&gt;&lt;h3 id=&quot;1-Project-Ove</summary>
      
    
    
    
    <category term="Literature Review" scheme="http://example.com/categories/Literature-Review/"/>
    
    
    <category term="Computer Vision" scheme="http://example.com/tags/Computer-Vision/"/>
    
    <category term="Research" scheme="http://example.com/tags/Research/"/>
    
  </entry>
  
  <entry>
    <title>2020秋季《计算机体系结构》笔记</title>
    <link href="http://example.com/2020/12/07/arc_notes/"/>
    <id>http://example.com/2020/12/07/arc_notes/</id>
    <published>2020-12-07T03:32:26.000Z</published>
    <updated>2022-01-10T03:32:19.563Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Computer-Architecture-Course-Review"><a href="#Computer-Architecture-Course-Review" class="headerlink" title="Computer Architecture Course Review"></a>Computer Architecture Course Review</h2><p>LI QILIN @ CQU, Fall, 2020</p><h3 id="Leture-01-Quantitative-Approach"><a href="#Leture-01-Quantitative-Approach" class="headerlink" title="Leture 01. Quantitative Approach"></a>Leture 01. Quantitative Approach</h3><h4 id="1-1-Power-And-Energy"><a href="#1-1-Power-And-Energy" class="headerlink" title="1.1 Power And Energy"></a>1.1 Power And Energy</h4><h5 id="1-1-1-introduction"><a href="#1-1-1-introduction" class="headerlink" title="1.1.1 introduction"></a>1.1.1 introduction</h5><p>1.Thermal Design Power(TDP): Lower than peak power, higher than average power consumption.</p><p>2.Clock rate can be reduced dynamically to limit power consumption</p><p>3.功耗（power）、能耗（Energy），一般用<strong>Energy</strong>衡量处理器性能。</p><p>4.两种影响性能的power：dynamic、static.</p><blockquote><p>Dynamic power dissipated when transistors switch.(e.g: data dependent).<br>Static power is due to leakage current and proportional to the number of transistors on-chip.</p></blockquote><h5 id="1-1-2-dynamic-energy-and-power"><a href="#1-1-2-dynamic-energy-and-power" class="headerlink" title="1.1.2 dynamic energy and power"></a>1.1.2 dynamic energy and power</h5><p>1.Dynamic Energy:</p><p>Transistor switch from 0 -&gt; 1 -&gt; 0 or 1 -&gt; 0 -&gt; 1:</p><script type="math/tex; mode=display">Energy_{dynamic} = CV^2</script><p>2.Dynamic Power:</p><script type="math/tex; mode=display">Power_{dynamic}={1\over2}CV^2f</script><p><em>Reducing clock rate reduces power, not energy!</em></p><h4 id="1-2-Performance-Metrics"><a href="#1-2-Performance-Metrics" class="headerlink" title="1.2 Performance Metrics"></a>1.2 Performance Metrics</h4><p>1.Machine X is n times faster than machine Y:</p><p><img src="/2020/12/07/arc_notes/image-20201207093805956.png" alt="image-20201207093805956" style="zoom:30%;"></p><h4 id="1-3-Principle-of-Locality"><a href="#1-3-Principle-of-Locality" class="headerlink" title="1.3 Principle of Locality"></a>1.3 Principle of Locality</h4><p>1.Temporal Locality: again sometime in the near future.</p><p>2.Spatial Locality: a higher resource near it was just refe.</p><p>E.g:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ( i= <span class="number">0</span> ; i&lt; <span class="number">20</span> ; i++)</span><br><span class="line"><span class="keyword">for</span>( j=<span class="number">0</span>; j&lt;<span class="number">10</span>; j++)</span><br><span class="line">a[i]=a[i]*j;</span><br></pre></td></tr></table></figure><p>Spatial: 外层循环，下一次即将访问是a[i+1]，与a[i]在物理存储上是连续的；<br>Temporal：内层循环，下一次又要使用a[i]是之前使用过的数据。</p><h4 id="1-4-Amdahl’s-Law"><a href="#1-4-Amdahl’s-Law" class="headerlink" title="1.4 Amdahl’s Law"></a>1.4 Amdahl’s Law</h4><p>1.the OVERALL speedup:</p><p><img src="/2020/12/07/arc_notes/image-20201207095046112.png" alt="image-20201207095046112" style="zoom:37%;"></p><p>2.for component x is improved by Sx and affects a fraction Fx of the overall execution time:</p><script type="math/tex; mode=display">speedup = {1\over (1-Fx) + Fx/Sx}</script><p>E.g:</p><blockquote><p>If we optimize the module for the floating-point instructions by a factor of 2, but the system will normally run programs with only 20% of floating point instructions then the speedup is :</p></blockquote><p><em>注：by a factor of X是指缩小成1/X倍</em></p><script type="math/tex; mode=display">speedup = {1\over (1-20\%) + 20\%/2} = 1.111</script><h4 id="1-5-CPU-Time"><a href="#1-5-CPU-Time" class="headerlink" title="1.5 CPU Time"></a>1.5 CPU Time</h4><p>1.Classification:</p><blockquote><p>User CPU time: spent in the user program.</p><p>System CPU time: spent in the OS performing tasks required by the program</p></blockquote><p><strong>user CPU time is to assess CPU performance. (aka CPU time)</strong></p><p>2.Formula:</p><script type="math/tex; mode=display">CPU \ time=CCP \times CCT=CCP / Frequency</script><p>3.Three Main Factors:</p><p>​    a. IC=instruction count, number of instructions executed for a program.</p><p>​    b. CPI=clock cycles per instruction, average number of clock cycles per instruction.</p><p>​    c. CCT=clock cycle time.</p><p> CPU Time equally depends on these three factors, and based on the above:</p><script type="math/tex; mode=display">CPU \ time = IC\times CPI \times CCT</script><p><em>note: CPI越小越好，但是不一定1最好，因为超标量处理器一次可以issue多条，CPI&lt;1.</em></p><p>4.Dependencies:</p><div class="table-container"><table><thead><tr><th></th><th>IC</th><th>CPI</th><th>CCT</th></tr></thead><tbody><tr><td>Program</td><td>✔️</td><td></td><td></td></tr><tr><td>Compiler</td><td>✔️</td><td></td><td></td></tr><tr><td>ISA</td><td>✔️</td><td>✔️</td><td></td></tr><tr><td>HW organization</td><td></td><td>✔️</td><td>✔️</td></tr><tr><td>HW technology</td><td></td><td></td><td>✔️</td></tr></tbody></table></div><p>E.g:</p><p><img src="/2020/12/07/arc_notes/image-20201207104233012.png" alt="image-20201207104233012" style="zoom:30%;"></p><script type="math/tex; mode=display">CPI_{average}=4.0 \times 25\%+1.33\times 75\%=2.0</script><p>We can first calculate that CPI with FPSQR’s decrease is:</p><script type="math/tex; mode=display">CPI_{new1} = 2.0 - 2\%\times(20-2)=1.64</script><p>So the speedup rate for FPSQR is:</p><script type="math/tex; mode=display">speedup_1 = CPI_{average}/CPI_{new1}=</script><p>While for decrease in FP, new CPI is:</p><script type="math/tex; mode=display">CPI_{new2}=25\%\times2.5+75\%\times1.33=1.625</script><p>So the speedup rate for FP is:</p><script type="math/tex; mode=display">speedup_2=CPI_{average}/CPI_{new2}=</script><h3 id="Lecture02-Instruction-Set-Architecture"><a href="#Lecture02-Instruction-Set-Architecture" class="headerlink" title="Lecture02. Instruction Set Architecture"></a>Lecture02. Instruction Set Architecture</h3><h4 id="2-1-Operand-Storage"><a href="#2-1-Operand-Storage" class="headerlink" title="2.1 Operand Storage"></a>2.1 Operand Storage</h4><p>​    a. Memory: Need to represent the address with a few bits.</p><p>​    b. Register: Short register addressing, AC</p><p>​    c. Stack : Does not need for addresses.</p><p><em>Whatever the ISA, operand’s address needs to be mapped into an Effective Address of the physical storage location!</em></p><h4 id="2-2-Kinds-of-Addressing-Mode"><a href="#2-2-Kinds-of-Addressing-Mode" class="headerlink" title="2.2 Kinds of Addressing Mode"></a>2.2 Kinds of Addressing Mode</h4><p><img src="/2020/12/07/arc_notes/image-20201207111224921.png" alt="image-20201207111224921" style="zoom:33%;"></p><div class="table-container"><table><thead><tr><th>Addressing Mode</th><th>value</th><th>Addressing Mode</th><th>value</th></tr></thead><tbody><tr><td>Register direct</td><td>[Ri]</td><td>Scaled Index</td><td>M[[Ri] + [Rj]*d + v], eg. d=8</td></tr><tr><td>Immediate (literal)</td><td>v</td><td>Autoincrement</td><td>M[[Ri] + 1]</td></tr><tr><td>Direct (absolute)</td><td>M[Ri]</td><td>Autodecrement</td><td>M[[Ri] - 1]</td></tr><tr><td>Register indirect</td><td>M[[Ri]]</td><td>Memory Indirect</td><td>M[M[Ri]]</td></tr><tr><td>Base+Displacement</td><td>M[[Ri] + v]</td><td>Base+Index</td><td>M[[Ri] + [Rj]]</td></tr></tbody></table></div><p>note: M is memory, R is register, [] get the value in it.</p><p>the following figure show the mode of finding addr’s value:</p><p><img src="/2020/12/07/arc_notes/image-20201207112207854.png" alt="image-20201207112207854" style="zoom:33%;"></p><p><img src="/2020/12/07/arc_notes/image-20201207112306311.png" alt="image-20201207112306311" style="zoom:30%;"></p><h4 id="2-3-MIPS"><a href="#2-3-MIPS" class="headerlink" title="2.3 MIPS"></a>2.3 MIPS</h4><h5 id="2-3-1-Overview"><a href="#2-3-1-Overview" class="headerlink" title="2.3.1 Overview"></a>2.3.1 Overview</h5><p>1.Architecture: Register-to-Register (load-store)</p><p>2.Addressing modes:</p><ul><li>displacement (offset: 12 ~ 16 bits)</li><li>using PC-relative addressing, branch +/- 2^15 words from PC.</li><li>immediate (size 8-16 bits)</li><li>register indirect</li></ul><p>3.Data size &amp; type: Integers (8,16,32,64 size) and FP (64)</p><p>E.g: fill in the blanks of mode.</p><div class="table-container"><table><thead><tr><th>instruction</th><th>meaning</th><th>mode</th></tr></thead><tbody><tr><td>DADDI R3, R2, 7</td><td>R3 &lt;- [R2] + 7</td><td>immediate</td></tr><tr><td>LD R3, 100(R1)</td><td>R3 &lt;- M[[R1] + 100]</td><td>displacement</td></tr><tr><td>LD R3, 0(R1)</td><td>R3 &lt;- M[[R1]]</td><td>register indirect</td></tr><tr><td>LD R3, 1001(R0)</td><td>R3 &lt;- M[1001]</td><td>direct addressing</td></tr></tbody></table></div><p>注：第四条寄存器用的R0，里面存放的数值固定为0，所以这就是基地址为0的寻址了，叫做直接寻址，与第二条区分开。</p><h5 id="2-3-2-Instruction-format"><a href="#2-3-2-Instruction-format" class="headerlink" title="2.3.2 Instruction format"></a>2.3.2 Instruction format</h5><p><img src="/2020/12/07/arc_notes/image-20201207113849175.png" alt="image-20201207113849175"></p><p>Load：Memory(Reg(j)) ———-&gt; Reg(i)</p><p>Store: Reg’s value(i) ———&gt; Memory(Reg(j)) (寄存器对应指令，不要写反了)</p><p>E.g: write mips code</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Loop: add $t1, $s3, $s3    #starts from 80000</span><br><span class="line">add $t1, $t1, $t1</span><br><span class="line">add $t1, $t1, $s6</span><br><span class="line">lw  $t0, 0($t1)</span><br><span class="line">bne $t0, $s5, Exit</span><br><span class="line">add $s3, $s3, $s4</span><br><span class="line">j   Loop</span><br><span class="line">Exit:</span><br></pre></td></tr></table></figure><p>(1)  |  add  | s3 | s3 | t1 | 0 |   32   |</p><p>(2)  |  add  | t1 | t1 | t1 | 0 |   32   |</p><p>(3)  |  add  | t1 | t6 | t1 | 0 |   32   |</p><p>(4)  |   lw    | t1 | t0 |         0          |</p><p>(5)  |  bne  | t0 | s5 |         <strong>2</strong>          |</p><p>(6)  |  add  | s3 | s4 | s3 | 0 |   32   |</p><p>(7)  |    j     |            <strong>20000</strong>             |</p><p>Note: MIPS uses bytes address, not word. in the instruction, write pseudodirect address (word addr)</p><h5 id="2-3-3-MIPS-addressing-mode"><a href="#2-3-3-MIPS-addressing-mode" class="headerlink" title="2.3.3 MIPS addressing mode"></a>2.3.3 MIPS addressing mode</h5><ul><li>Immediate: ADDI R3, R2, #7</li><li>displacement: LD R3, 1001(R1) </li><li>direct: LD R3, 100(R0)</li><li>indirect: LD R3, 0(R3)</li></ul><h4 id="2-4-Interpreting-Memory-Addressing"><a href="#2-4-Interpreting-Memory-Addressing" class="headerlink" title="2.4 Interpreting Memory Addressing"></a>2.4 Interpreting Memory Addressing</h4><p><img src="/2020/12/07/arc_notes/image-20201207113633122.png" alt="image-20201207113633122" style="zoom:40%;"></p><p>note: Memory <strong>word</strong> is addressed by the <strong>byte</strong> at the lowest address.</p><h3 id="Lecture-03-Pipelining"><a href="#Lecture-03-Pipelining" class="headerlink" title="Lecture 03. Pipelining"></a>Lecture 03. Pipelining</h3><h4 id="3-1-Pipelining-processing"><a href="#3-1-Pipelining-processing" class="headerlink" title="3.1 Pipelining processing"></a>3.1 Pipelining processing</h4><ol><li>Instruction fetch (IF)</li><li><p>Instruction decode and register operand fetch (ID/RF)</p></li><li><p>Execute/Evaluate memory address (EX/AG)</p></li><li><p>Memory operand fetch (MEM)</p></li><li><p>Store/writeback result (WB) </p></li></ol><blockquote><p>note: 1. Pipelining doesn’t help latency of <strong>single</strong> task, it helps throughput of entire workload.</p><p>2.Pipeline rate limited by slowest pipeline stage.</p><p>3.Unbalanced lengths of pipe stages reduces speedup.</p><p>4.Time to “fill” pipeline and time to “drain” it reduces speedup.</p></blockquote><h4 id="3-2-Design-Issues"><a href="#3-2-Design-Issues" class="headerlink" title="3.2 Design Issues"></a>3.2 Design Issues</h4><p>IDEAL:</p><p><img src="/2020/12/07/arc_notes/image-20201207153730999.png" alt="image-20201207153730999" style="zoom:33%;"></p><h5 id="3-2-1-Performance-issue"><a href="#3-2-1-Performance-issue" class="headerlink" title="3.2.1 Performance issue"></a>3.2.1 Performance issue</h5><p>(1)  Pipelining can be seen as either:</p><ul><li>decreasing the CPI of a multi-cycle un-pipelined implementation;</li><li>decreasing the CCT of a single-cycle un-pipelined implementation.</li></ul><p>理解：流水线对性能的提升体现在不同的情景下，其中降CPI是多指令中体现，降CCT是单条指令中体现出来的。降CCT其实就是降主频，un-pipelined的上升沿要做的事情比较多，但pipeline划分成一个上升沿只干一件事，就比无流水线的时钟长度短。</p><p>(2) with STALLS:</p><script type="math/tex; mode=display">Speedup={CPI\ unpipelined\over 1+pipeline\ stall \ cycle \ per \ instruction }={CPI\ depth\over 1+pipeline\ stall \ cycle \ per \ instruction }</script><h5 id="3-2-2-Performance-Limitation"><a href="#3-2-2-Performance-Limitation" class="headerlink" title="3.2.2 Performance Limitation"></a>3.2.2 Performance Limitation</h5><ul><li>Imbalance among pipe stages : limits cycle time to slowest stage</li><li>Pipelining overhead: Pipeline register delay or Clock skew</li><li>Clock cycle &gt; clock skew + latch overhead</li><li><strong>hazards</strong></li></ul><h4 id="3-3-Pipeline-Hazards"><a href="#3-3-Pipeline-Hazards" class="headerlink" title="3.3 Pipeline Hazards"></a>3.3 Pipeline Hazards</h4><p>(1) Structural Hazards: 资源冲突。the HW cannot support all possible instruction combinations <strong>simultaneously</strong>.</p><p>举例：Some pipelined processors have shared a single memory for data and instructions. you can’t fetch instrcution if now is reading data from memory.</p><p>solution: STALLs (aka BUBBLEs) / increase CPI</p><p>E.g: PPT 49</p><p>2) Data Hazards:上条正在更新的内容还没有写入下一条就要用。an instruction depends on the result of a previous instruction</p><p>举例：ADDI follows a SD</p><p>solution: Forwading (or bypassing) If the forwarding hardware detects that the previous ALU operation has written the register corresponding to a source for the current ALU operation, control logic selects the forwarded result as the ALU input rather than the value read from the register file.</p><p><em>来自EX/MEM和MEM/WB的寄存器的ALU结果被反馈到ALU的输入端。</em></p><p>WARNING：Not all Data Hazards can be solved by Forwarding. LD ———- ADDI. should use STALL</p><p>(3) Control Hazards: PC的更新及时性。arise from the pipelining of branches, jumps and CPU can’t determine which instruction to take.</p><p>举例：Branch (taken? Not taken?)</p><p>solution: </p><p>​    a. GUESS: if guess wrong, undo the steps (见Lecture05)</p><p>​    b. Stalls: </p><p>​    c. Use a delayed branch:</p><p>​            i. 用没用的指令作为delay slot；</p><p>​            ii. 用跳转目的地中无关的内容作为；</p><p>​            iii. 用不跳转的部分指令作为。    </p><p>​    d. 循环展开+调整指令顺序.</p><p>E.g: Write a code that the branch instruction in ID causes a RAW hazard, even with data forwarding.</p><p>习题：PPT 64~70（重点！！）</p><h3 id="Lecture-04-ILP"><a href="#Lecture-04-ILP" class="headerlink" title="Lecture 04. ILP"></a>Lecture 04. ILP</h3><h4 id="4-1-Instruction-Level-Parallelism"><a href="#4-1-Instruction-Level-Parallelism" class="headerlink" title="4.1 Instruction-Level Parallelism"></a>4.1 Instruction-Level Parallelism</h4><p><strong>ILP</strong>: overlap the execution of instructions</p><ul><li>partially (through pipelining)</li><li>completely (through issuing on multiple functional units)</li></ul><h4 id="4-2-Dependences-versus-Hazards"><a href="#4-2-Dependences-versus-Hazards" class="headerlink" title="4.2 Dependences versus Hazards"></a>4.2 Dependences versus Hazards</h4><ol><li>Dependences are a property of programs.</li><li>Based on the given pipeline implementation a data dependency may result in an actual hazard being detected and a possible stall.</li><li>Dependency ≡ hazard potential.</li><li>Dependences determine the order in which results must be computed.</li><li>Dependences set an upper bound on the amount of instruction-level parallelism that can be exploited.</li></ol><h4 id="4-3-Dependency-Category"><a href="#4-3-Dependency-Category" class="headerlink" title="4.3 Dependency Category"></a>4.3 Dependency Category</h4><ul><li>True Data Dependency: may lead to RAW </li><li>Name Dependence: <ul><li>Anti-dependence: may lead to WAR</li><li>output dependence: may lead to WAW</li></ul></li></ul><p><em>note: WAW or WAR can be avoided by optimized algorithm, while RAW is the truth dependency that can’t be omitted.</em></p><blockquote><p>注：这里把我绕晕了。RAW是read after write，意思是“写操作在读操作的前面，但是有可能还没有写完，就开始读”，就会造成冒险。而WAR显然就是写指令在读指令后面，然而有可能还没读完就开始写。这个没理解清楚，后面的两个算法都不懂。</p></blockquote><h4 id="4-4-The-Scoreboard-Approach"><a href="#4-4-The-Scoreboard-Approach" class="headerlink" title="4.4 The Scoreboard Approach*"></a>4.4 The Scoreboard Approach*</h4><h5 id="4-4-1-Stages"><a href="#4-4-1-Stages" class="headerlink" title="4.4.1 Stages"></a>4.4.1 Stages</h5><ol><li>ISSUE: instruction decoding. <em>Check</em> <strong>structural hazards</strong> and <strong>WAW</strong>.</li><li>READ OPERANDS: wait for operand. <em>Resolve</em> <strong>RAW hazards</strong></li><li>EXECUTION: inform upon completion.</li><li>WRITE BACK: <em>Check</em> <strong>WAR hazards</strong></li></ol><h5 id="4-4-2-Scoreboard-outlook"><a href="#4-4-2-Scoreboard-outlook" class="headerlink" title="4.4.2 Scoreboard outlook"></a>4.4.2 Scoreboard outlook</h5><p><img src="/2020/12/07/arc_notes/image-20201207210159451.png" alt="image-20201207210159451" style="zoom:40%;"></p><h5 id="4-4-3-Scoreboard-Explain"><a href="#4-4-3-Scoreboard-Explain" class="headerlink" title="4.4.3 Scoreboard Explain"></a>4.4.3 Scoreboard Explain</h5><p><img src="/2020/12/07/arc_notes/image-20201207210942981.png" alt="image-20201207210942981" style="zoom:60%;"></p><h5 id="4-4-4-how-to-avoid"><a href="#4-4-4-how-to-avoid" class="headerlink" title="4.4.4 how to avoid?"></a>4.4.4 how to avoid?</h5><p>在Write阶段，如果目标寄存器是别人的false 可以写（避免了WAR）</p><p>在Decode阶段，如果两个都true了可以读（避免了RAW）读完以后设置成false</p><p>在Issue阶段，如果目标寄存器没有被别人正在写，可以开始（避免了WAW）</p><h3 id="Lecture-05-Dynamic-Branch-Prediction"><a href="#Lecture-05-Dynamic-Branch-Prediction" class="headerlink" title="Lecture 05. Dynamic Branch Prediction"></a>Lecture 05. Dynamic Branch Prediction</h3><p>(复习时，建议先看Lec 06再看05)</p><h4 id="5-1-Branch-prediction-strategy"><a href="#5-1-Branch-prediction-strategy" class="headerlink" title="5.1 Branch prediction strategy"></a>5.1 Branch prediction strategy</h4><ul><li><p>STATIC (Decided before runtime)</p><ul><li>Always-Not Taken / Always-Taken</li><li>Backwards Taken, Forward Not Taken</li></ul></li><li><p>Dynamic(Prediction decisions may change during the execution of the program)</p></li></ul><h4 id="5-2-1-bit-Predictor"><a href="#5-2-1-bit-Predictor" class="headerlink" title="5.2 1-bit Predictor"></a>5.2 1-bit Predictor</h4><p><em>考试中若出现此题型会给出状态机.</em></p><p><img src="/2020/12/07/arc_notes/image-20201208091500097.png" alt="image-20201208091500097" style="zoom:45%;"></p><h4 id="5-3-Branch-History-Table"><a href="#5-3-Branch-History-Table" class="headerlink" title="5.3 Branch-History Table"></a>5.3 Branch-History Table</h4><p>Implemented as a small memory indexed by a portion (usually some low-significant bits) of the address of the branch instruction. That means, the buffer stores for each address the prediction result.</p><h4 id="5-4-2-bit-Predictor"><a href="#5-4-2-bit-Predictor" class="headerlink" title="5.4 2-bit  Predictor"></a>5.4 2-bit  Predictor</h4><p><img src="/2020/12/07/arc_notes/image-20201208112748770.png" alt="image-20201208112748770"></p><p><em>note: 实验指导书的FSM（上图）与PPT中的不一样，具体的还是看题目给的是什么.</em></p><p>A 2-bit predictor helps to insist on previous prediction for a longer time. it’s not always better than one bit.</p><p>E.g:</p><p>A snapshot of the taken/not-taken behavior of a branch is:<br>… T T T T T T T T <strong>N N T T N N T N N T</strong><br>If the branch predictor used is a 2-bit saturating counter, how many of the last ten branches are predicted correctly?</p><blockquote><p>上图的FSM：ST WT WN WT ST WT WN WT WN SN</p><p>PPT 的FSM：ST WT SN WN ST WT SN WN SN SN</p></blockquote><h4 id="5-5-Correlating-Branch-Predictors"><a href="#5-5-Correlating-Branch-Predictors" class="headerlink" title="5.5 Correlating Branch Predictors"></a>5.5 Correlating Branch Predictors</h4><h5 id="5-5-1-limitations-on-previous-methods"><a href="#5-5-1-limitations-on-previous-methods" class="headerlink" title="5.5.1 limitations on previous methods"></a>5.5.1 limitations on previous methods</h5><p>The 2-bit predictor schemes use only the <strong>recent behavior of a single branch</strong> to predict the future behavior of that branch. Increasing to 3-bit or more does not help much!</p><h5 id="5-5-2-Proposal-of-Correlating-Predictor"><a href="#5-5-2-Proposal-of-Correlating-Predictor" class="headerlink" title="5.5.2 Proposal of Correlating Predictor"></a>5.5.2 Proposal of Correlating Predictor</h5><p>An (m,n) 2-level predictor uses the behavior of the last m branches to choose from $2^m$ branch predictors, each of which is an n-bit predictor for a single branch. </p><p>e.g</p><p>assume that A(1, 1)predictor is initialized as (NT/NT). m=1, n=1</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b1BNEZ R1, L1 #if(d == 0)</span><br><span class="line">DADDIU R1, R0, #1 #d = 1</span><br><span class="line">L1:...</span><br><span class="line">b2BNEZ R3, L2 #if(d == 1)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><div class="table-container"><table><thead><tr><th>d=?</th><th>b1 pred</th><th>b1 action</th><th>b1 new pred</th><th>b2 pred</th><th>b2 action</th><th>b2 new pred</th></tr></thead><tbody><tr><td>2</td><td>NT/NT</td><td>T</td><td>T/NT</td><td>NT/<strong>NT</strong></td><td>T</td><td>NT/T</td></tr><tr><td>0</td><td>T/NT</td><td>NT</td><td>T/NT</td><td>NT/T</td><td>NT</td><td>NT/T</td></tr><tr><td>2</td><td>T/NT</td><td>T</td><td>T/NT</td><td>NT/T</td><td>T</td><td>NT/T</td></tr><tr><td>0</td><td>T/NT</td><td>NT</td><td>T/NT</td><td>NT/T</td><td>NT</td><td>NT/T</td></tr></tbody></table></div><h3 id="Lecture-06-Tomasulo’s-Algorithm"><a href="#Lecture-06-Tomasulo’s-Algorithm" class="headerlink" title="Lecture 06. Tomasulo’s Algorithm"></a>Lecture 06. Tomasulo’s Algorithm</h3><h4 id="6-1-Main-features"><a href="#6-1-Main-features" class="headerlink" title="6.1 Main features"></a>6.1 Main features</h4><ul><li><strong>distributed</strong> control and buffering with reservation stations; （没有集中的控制单元）</li><li>dynamically replace register specification in instruction with value or pointer to functional unit producing the value (register renaming);</li><li>tracking when operands are available to handle RAWs;</li><li>more reservation stations than registers.</li></ul><h4 id="6-2-Assumption"><a href="#6-2-Assumption" class="headerlink" title="6.2 Assumption"></a>6.2 Assumption</h4><ul><li>Distributed control based on reservation station tag fields;</li><li>Register file bypassed in broadcasting to reservation stations via Common Data Bus;(使用了总线，当某一个数据计算结束后，结果马上广播给所有要用它的数据单元);</li><li>stall issuing operations when there is a pending branch in the pipeline(因为数据的变化在EX执行前通知到各FU即可，所以issue可以照常).</li></ul><h4 id="6-3-Stages"><a href="#6-3-Stages" class="headerlink" title="6.3 Stages"></a>6.3 Stages</h4><ol><li><p>ISSUE</p><p>i. check for availability of matching reservation station (structural hazards); </p><p>ii. check for operands in the register file and read them if available (register renaming handles <strong>WAR</strong> and <strong>WAW</strong> hazards) </p><blockquote><p>注意：tomasulo的第一阶段实际上是把scoreboard的1、2阶段结合了。</p><p>scoreboard的第一阶段是进行资源冲突检测（即FU是否可用，这样可以避免structrual hazard）以及目标寄存器是否正在为其他在执行指令的目标（避免WAW）</p><p>scoreboard的第二阶段是读指令operand里的数据，如果这些数据正在被其他单元操作，就不读，这样可以避免RAW</p><p>而不同之处在于，托马索罗有保留站，当时issue进来r1的值会保留在保留站里，后面即使改变了也不要紧，这个指令的单元中r1依旧是之前读出来的值，后续读的都是rename了，不再是之前的了。</p></blockquote></li><li><p>EXECUTION</p><p>i. monitor CDB for missing operands;</p><p>ii. start execution when operands are available in reservation stations (<strong>RAW</strong> hazards).</p></li><li><p>WRITE BACK</p><p> i. use CDB to broadcast the result to register file and reservation stations ( including store buffers to write memory)</p></li></ol><h4 id="6-4-Explanation-of-T’s-Chart"><a href="#6-4-Explanation-of-T’s-Chart" class="headerlink" title="6.4 Explanation of T’s Chart"></a>6.4 Explanation of T’s Chart</h4><p><img src="/2020/12/07/arc_notes/image-20201208094940662.png" alt="image-20201208094940662"></p><ol><li>Op:    Operation to perform in the unit (e.g., + or –)</li><li>Vj, Vk: <strong>Value</strong> of Source operands (Store buffers has V field, result to be stored)</li><li>Qj, Qk: Reservation stations producing source registers (value to be written)<ul><li>No ready flags as in Scoreboard; Qj,Qk=0 =&gt; ready</li><li>Store buffers only have Qi for RS producing result</li></ul></li><li>A: to hold memory address for load and store instructoins</li><li>Busy: Indicates reservation station or FU is busy</li></ol><h4 id="6-5-Tomasulo-VS-Scoreboard"><a href="#6-5-Tomasulo-VS-Scoreboard" class="headerlink" title="6.5 Tomasulo VS. Scoreboard"></a>6.5 Tomasulo VS. Scoreboard</h4><div class="table-container"><table><thead><tr><th></th><th>Tomasulo’s Algorithm</th><th>Scoreboard</th></tr></thead><tbody><tr><td>introduced with</td><td>IBM</td><td>CDC</td></tr><tr><td>resoures</td><td>3 adders, 2mul/div, 6 load, 3 store</td><td>7 int units, 4 FP units, 5 mem</td></tr><tr><td>Max window size</td><td>14</td><td>5</td></tr><tr><td>structural hazards</td><td>Issue: not allow to excute if FU is occupied</td><td>Issue: not allow to excute if FU is occupied</td></tr><tr><td>WAR hazards</td><td>Issue: avoid by register renaming</td><td>Write Back</td></tr><tr><td>WAW hazards</td><td>Issue: avoid by register renaming</td><td>Issue: wait untill last write Register finish.</td></tr><tr><td>Control</td><td>based on reservation station</td><td>scoreboard control module</td></tr><tr><td>Communication</td><td>Broadcasting</td><td>buses from/ to register</td></tr><tr><td>RAW hazards</td><td>Execute: finish write, read</td><td>Decode: register ready, go next instruction</td></tr></tbody></table></div><h5 id="6-5-1-breif-review-of-SCOREBOARD"><a href="#6-5-1-breif-review-of-SCOREBOARD" class="headerlink" title="6.5.1 breif review of SCOREBOARD"></a>6.5.1 breif review of SCOREBOARD</h5><p>集中控制部件，记录了数据寄存器和多个处理部件状态的变化情况。</p><ul><li>stages:<ul><li>issue: 检查结构冒险（FU冲突）、WAW（本指令目标寄存器不是其它正在执行的目标），如果存在，指令<strong>暂停发射</strong>；</li><li>read operand: 检查RAW（本指令要读的寄存器是否是其他正在执行的目标），如果有，<strong>停顿</strong>；</li><li>execute：得到结果时，FU通知完成（即总表上最后一个周期记录结果）；</li><li>write back：检查WAR，如果写的目标寄存器被别人访问，<strong>暂停</strong>。</li></ul></li><li>pros:<ul><li>动态调度方法利用了程序中存在的ILP，通过乱序执行，达到减少RAW造成的停顿周期</li></ul></li><li>cons:<ul><li>指令级并行性不高(需要进一步研究开发更多的ILP)</li><li>记分牌表项较少(可增加硬件加以解决)</li><li>功能单元少(可增加硬件加以解决)</li><li>记分牌无法消除WAR和WAW两种相关性</li></ul></li></ul><h5 id="6-5-2-breif-review-of-TOMASULO"><a href="#6-5-2-breif-review-of-TOMASULO" class="headerlink" title="6.5.2 breif review of TOMASULO"></a>6.5.2 breif review of TOMASULO</h5><p>寄存器重命名功能由保留站提供，意思是需要的数据结果被放在这个保留站里面，命了名（独此计算单元所有）</p><ul><li>stages:<ul><li>Issue: 检查结构冒险（FU冲突）、WAW（本指令目标寄存器不是其它正在执行的目标）、WAR（可以先读，因为当前读到的结果被存在保留站里了，而寄存器内值的写（改变）不会影响到保存站里的值）；</li><li>execute: 检查RAW，若有一个或几个操作数未就绪，等待计算该操作数，同时监控CDB；</li><li>write back：广播计算结果（播给等待此结果的保留站）</li></ul></li></ul><h5 id="6-5-3-contrast"><a href="#6-5-3-contrast" class="headerlink" title="6.5.3 contrast"></a>6.5.3 contrast</h5><p>相同之处：</p><ol><li>两者消除RAW的方法都一样，就是动态调度消除RAW。</li><li>对于结构冒险，他们都stall。</li><li>都是乱序执行。</li></ol><p>不同之处：</p><ol><li>scoreboard（以下简称SB）能检测WAW和WAR，检测到了就stall，所以不能消除，但是tomasulo（下称TA）使用了重命名方法，可以消除；</li><li>硬件上，TA是一种分布式方法，通过每一个功能单元的保留站消除了waw和war；而SB是集中式的，只有一个记分牌；</li><li>写回方式上，TA是用总线CDB直接广播的，不需要经过寄存器；SB要写寄存器，因此可能造成等待结果而停顿WB阶段的现象。</li></ol><h3 id="Lecture-07-Memory-Hierarchy-Design"><a href="#Lecture-07-Memory-Hierarchy-Design" class="headerlink" title="Lecture 07. Memory Hierarchy Design"></a>Lecture 07. Memory Hierarchy Design</h3><h4 id="7-1-Locality-on-Cache"><a href="#7-1-Locality-on-Cache" class="headerlink" title="7.1 Locality on Cache"></a>7.1 Locality on Cache</h4><ol><li>Temporal: cache provides faster access to a smaller subset of the main memory which contains copies that <strong>recently used</strong>.</li><li>Spatial: contiguous memory cells is retrieved from the main memory.</li></ol><h4 id="7-2-Cache-Tech"><a href="#7-2-Cache-Tech" class="headerlink" title="7.2 Cache Tech."></a>7.2 Cache Tech.</h4><h5 id="7-2-1-Concepts-of-cache"><a href="#7-2-1-Concepts-of-cache" class="headerlink" title="7.2.1 Concepts of cache"></a>7.2.1 Concepts of cache</h5><ol><li>The most popular scheme is set associative, where a set is a group of blocks.</li></ol><blockquote><p>A set with N blocks is called N-way associative </p></blockquote><ol><li>A block is first mapped onto a set, and then the block can be placed anywhere within that set.</li><li><img src="/Users/liqilin/Library/Application Support/typora-user-images/image-20201208171544187.png" alt="image-20201208171544187"></li><li>Finding a block consists of first mapping the block address to the set and then searching the set—usually in parallel—to find the block. </li></ol><h5 id="7-2-2-terminology"><a href="#7-2-2-terminology" class="headerlink" title="7.2.2 terminology"></a>7.2.2 terminology</h5><ul><li>Cache hit<ul><li>CPU find the requested data item in the cache</li></ul></li><li>Cache Miss<ul><li>CPU doesn’t find the requested data item in the cache</li></ul></li><li>Miss panalty<ul><li>time to replace a block in the cache (plus time to deliver data item to CPU) </li><li>time depends on both latency &amp; bandwidth</li><li>handled by hardware that stalls the memory unit (and, therefore, the whole instruction processing in case of simple single-issue uP)</li></ul></li><li>Block</li><li>Set</li></ul><p><img src="/2020/12/07/arc_notes/image-20201208173455175.png" alt="image-20201208173455175" style="zoom:50%;"></p><h4 id="7-3-Direct-Mapping"><a href="#7-3-Direct-Mapping" class="headerlink" title="7.3 Direct Mapping"></a>7.3 Direct Mapping</h4><p><img src="/2020/12/07/arc_notes/image-20201208173630145.png" alt="image-20201208173630145" style="zoom:33%;"></p><p>Each memory block is mapped to one cache entry.</p><p>in direct mapping, <strong>a block is a word.</strong>(4 bytes, normally) so the offset if log(4) = 2</p><p>e.g: ppt 32</p><p><strong>pros and cons</strong>:</p><ul><li>Simple, and Inexpensive</li><li>Fixed location for given block<ul><li>If a program accesses 2 blocks that map to the same line repeatedly, cache misses are very high</li></ul></li></ul><p><em>note: offset refers to 字节偏移量!</em></p><p>mapping process：先查index，再查tag，最后是block中的offset。</p><h4 id="7-4-Fully-Associative"><a href="#7-4-Fully-Associative" class="headerlink" title="7.4 Fully Associative"></a>7.4 Fully Associative</h4><p><img src="/2020/12/07/arc_notes/image-20201208193842341.png" alt="image-20201208193842341" style="zoom:33%;"></p><p>Each block of main memory maps to any cache line. CPU chooses which line to map. 没有index，只有tag和block offset。</p><p><strong>pros and cons: </strong></p><ul><li>Full flexibility on determining the location in cache. </li><li>Expensive: Every line’s tag is examined for a match; Cache searching gets slow!</li></ul><h4 id="7-5-Set-Associative-Cache"><a href="#7-5-Set-Associative-Cache" class="headerlink" title="7.5 Set Associative  Cache"></a>7.5 Set Associative  Cache</h4><p><img src="/2020/12/07/arc_notes/image-20201208193922573.png" alt="image-20201208193922573" style="zoom:33%;"></p><ol><li><p>Cache is organized into sets where each set has 2, 4, 8 or more blocks: </p><ul><li>Each block is mapped to a set, and can <strong>be placed anywhere</strong> in that set. </li><li>The cache using m blocks per set is called m-way cache. </li><li>The number of sets is: L/m. Hence the set index is lg(L)-lg(m);</li><li>It is a trade-off between Direct Map (1-way) and Full Associative Map (All-way). </li></ul></li><li><p>When we place a block to a cache line, the block address is split into two parts:</p><p>(1) The LSB of lg(L)-lg(m) bits in block address tells the cache set the block maps to.</p><p>(2) The rest MSB bits, N-lg(w)-lg(L)-lg(m) in block address becomes its tag. </p></li></ol><p><em>note: the finding process is, 先找set index，再用tag匹配block块，再用block offset看是在block中的哪一个byte。</em></p><p>e.g: We will use the following architecture:</p><p>Cache of 64 kByte, cache block of 4 bytes, 16MBytes main memory and 24 bit address fro the cache. tell the bit number of tag, index and offset in direct map, 2 set associative and fully associative.</p><script type="math/tex; mode=display">block\ num = 64\ kBytes / 4\ bytes=2^{14}</script><script type="math/tex; mode=display">offset=lg(W)+lg(w/W)=lg(W)=lg(4)=2</script><p>1.direct map:</p><script type="math/tex; mode=display">index = lg(block\ num) = 14</script><script type="math/tex; mode=display">tag=len(addr)-index-offset=24-2-14=8</script><p>2.fully associative:</p><script type="math/tex; mode=display">index=0(no\ index \ for \ fully \ associative)</script><script type="math/tex; mode=display">tag = 24 - 2 = 22</script><p>3.2-set associative:</p><script type="math/tex; mode=display">set\ index = lg(block\ num/set) = 13</script><script type="math/tex; mode=display">tag=24-13-2=9</script><h4 id="7-6-A-Continuum"><a href="#7-6-A-Continuum" class="headerlink" title="7.6 A Continuum"></a>7.6 A Continuum</h4><ul><li>Direct Mapping gives fastest hit times, best for very large caches.</li><li>Full associativity gives lowest miss rate, best when miss penalty is very high</li><li>Increasing degree of associativity<ul><li>Typically decreases miss rate</li><li>increases hit time  (due to extra comparison/selection)</li><li>design trade-off between miss penalty and area/time overhead</li><li>tag变长，index变短。</li></ul></li></ul><p>e.g2: Quiz 4</p><h4 id="7-7-Cache-Write-Policies"><a href="#7-7-Cache-Write-Policies" class="headerlink" title="7.7 Cache Write Policies"></a>7.7 Cache Write Policies</h4><h5 id="7-7-1-policy"><a href="#7-7-1-policy" class="headerlink" title="7.7.1 policy"></a>7.7.1 policy</h5><ol><li>write back (write only cache block and set a “dirty bit” as reminder)<br>   – uses less memory bandwidth and it is a low-power approach</li><li><p>write through (write block on cache and memory simultaneously)</p><pre><code>      – requires a write buffer to minimize write stall</code></pre></li><li><p>write allocation：在写memory后是否为之在cache中分配位置</p><blockquote><ul><li>Write Allocate (typically used by write-back caches)</li><li>No-Write Allocate (typically used by write-through caches)</li></ul></blockquote></li></ol><p><em>note：看两个状态机！</em></p><p><em>note2：cache在读入的时候是读一块数据（为了保持局部性），写入的时候是写一个。这一点在写分配中也有体现。</em></p><h5 id="7-7-2-comparison"><a href="#7-7-2-comparison" class="headerlink" title="7.7.2 comparison"></a>7.7.2 comparison</h5><div class="table-container"><table><thead><tr><th></th><th>write-back</th><th>write-through</th></tr></thead><tbody><tr><td>pros</td><td>+ writes occur at the speed of the cache memory</td></tr></tbody></table></div><ul><li>multiple writes within a block require only one write to the lower-level memory</li><li>some writes don’t go to memory | + easier to implement than write back</li><li>cache is always clean, so read misses are faster as they never result in writes to lower level </li><li>next lower level has the most current copy of the data |<br>| cons | 如果某一时间断电，数据可能会丢失                可信度比较低 | 如果miss，采用不分配没有放回cache，写回的优势没有发挥出来    |</li></ul><h4 id="7-8-Cache-Performance"><a href="#7-8-Cache-Performance" class="headerlink" title="7.8 Cache Performance"></a>7.8 Cache Performance</h4><script type="math/tex; mode=display">CPU\ execution \ time=(CPU\ clock\ cycles+Memory\ stall\ cycles)\times CCT</script><h5 id="7-8-1-Memory-stall-cycles"><a href="#7-8-1-Memory-stall-cycles" class="headerlink" title="7.8.1 Memory stall cycles"></a>7.8.1 Memory stall cycles</h5><ul><li>IC: Instruction Count. </li><li>Memory Accesses: <ul><li>Each instr. has at least 1 memory access – loading the instr. </li><li>Some may have a data access</li></ul></li><li>Miss Rate: the fraction of cache accesses that result in a miss </li><li>Miss Penalty: an average # of stall cycles needed for a miss. </li></ul><p><img src="/2020/12/07/arc_notes/image-20201208205949463.png" alt="image-20201208205949463"></p><p>E.g: PPT 70 </p><h5 id="7-8-2-Average-memory-access-time"><a href="#7-8-2-Average-memory-access-time" class="headerlink" title="7.8.2 Average memory access time"></a>7.8.2 Average memory access time</h5><p><img src="/2020/12/07/arc_notes/arc_notesimage-20201208214021425.png" alt="image-20201208214021425" style="zoom:35%;"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Computer-Architecture-Course-Review&quot;&gt;&lt;a href=&quot;#Computer-Architecture-Course-Review&quot; class=&quot;headerlink&quot; title=&quot;Computer Architecture </summary>
      
    
    
    
    <category term="Notes" scheme="http://example.com/categories/Notes/"/>
    
    
    <category term="Computer Architecture" scheme="http://example.com/tags/Computer-Architecture/"/>
    
  </entry>
  
  <entry>
    <title>2020秋季《计算机网络》笔记</title>
    <link href="http://example.com/2020/11/01/network_notes/"/>
    <id>http://example.com/2020/11/01/network_notes/</id>
    <published>2020-11-01T03:32:26.000Z</published>
    <updated>2021-12-29T07:35:54.491Z</updated>
    
    <content type="html"><![CDATA[<h3 id="第一章-概述"><a href="#第一章-概述" class="headerlink" title="第一章 概述"></a>第一章 概述</h3><h4 id="1-1-网络概念及分类"><a href="#1-1-网络概念及分类" class="headerlink" title="1.1 网络概念及分类"></a>1.1 网络概念及分类</h4><h5 id="1-1-1-常用概念"><a href="#1-1-1-常用概念" class="headerlink" title="1.1.1 常用概念"></a>1.1.1 常用概念</h5><ul><li><strong>计算机网络：</strong>一组互联自治的计算机集合。连接介质：光纤、铜线、微波、红外、卫星等。</li><li><strong>互联网络</strong>：计算机网络的相连</li><li><strong>拓扑</strong>：信道的分布方式</li><li><strong>协议</strong>：一系列规则和规定的规范性描述，控制了两个或者多个对等实体之间的通信。<ul><li>协议三要素：语义、语法、同步</li></ul></li><li><strong>接口</strong>：同一节点内相邻两层之间交换信息的连接点（不可以跨层次定义）</li><li><strong>服务</strong>：服务是下层被上层体用的功能调用</li></ul><p>==服务是垂直的，协议是水平的==</p><h5 id="1-1-2-计算机网络的分类"><a href="#1-1-2-计算机网络的分类" class="headerlink" title="1.1.2 计算机网络的分类"></a>1.1.2 计算机网络的分类</h5><p>1、按照分布范围分类：广域网WAN、城域网MAN、局域网LAN、个人网PAN。</p><p><em>1m之内不称为计算机网络，叫处理器系统！</em></p><p>2、按照传输技术分类：广播式网络（共享一个通信信道）、点对点网络（一条物理线路连接一对计算机）。</p><p><em>局域网基本上采用的是广播式通信技术，广域网中的无线、卫星也是广播。</em></p><p>3、按照拓扑结构分类：总线形、星形、环形、网状形。</p><p><img src="/2020/11/01/network_notes/1.png" alt="pic1" style="zoom:33%;"></p><div class="table-container"><table><thead><tr><th>网络类型</th><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>总线型</td><td></td><td>简单、方便、节约</td><td>重负载时通讯效率低、对故障敏感</td></tr><tr><td>星形</td><td></td><td>便于集中管理</td><td>成本高、中心节点对故障敏感</td></tr><tr><td>环形</td><td>（比如令牌环网）</td><td>电缆长度短、适用于光纤</td><td>节点故障引起全网故障、监测困难、负载轻时利用率低</td></tr><tr><td>网状</td><td></td><td>可靠性高</td><td>控制复杂、线路成本高</td></tr></tbody></table></div><p>4、按照使用者分类：公用网、专用网</p><p>5、按照交换技术分类：</p><ul><li><p>电路交换网络 circuit switching</p><p>过程：建立连接-&gt;传输数据-&gt;释放连接 ，期间无论是否说话（传输信息）都占用了信道，连线效率低。</p></li><li><p>报文交换网络 message switching</p><p>pros：不需要建立连接，存储、转发机制有优势，并且不占用其他的信道</p><p>cons：报文的大小无法预知，存储跟不上数据的增大，且存储转换机制下可能有错</p></li><li><p>分组交换网络 packet switching</p><p>==存储-转发机制==~ 我理解的packet就是pipeline版的报文交换，因为它把数据分成了更小的部分。</p></li></ul><p><em>存储转发（Store and Forward）是计算机网络领域使用得最为广泛的技术之一，以太网交换机的控制器先将输入端口到来的数据包缓存起来，先检查数据包是否正确，并过滤掉冲突包错误。确定包正确后，取出目的地址，通过查找表找到想要发送的输出端口地址，然后将该包发送出去。</em></p><p><em>ref: 《王道考研》p4</em></p><h4 id="1-2-协议分层基本概念"><a href="#1-2-协议分层基本概念" class="headerlink" title="1.2 协议分层基本概念"></a>1.2 协议分层基本概念</h4><h5 id="1-2-1-分层的基本原则"><a href="#1-2-1-分层的基本原则" class="headerlink" title="1.2.1 分层的基本原则"></a>1.2.1 分层的基本原则</h5><ol><li>每层都实现一种相对独立的功能，降低大系统的复杂度。</li><li>个层之间界面自然清晰、易于理解，相互交流尽可能少。</li><li>各层功能的精确定义独立于具体的实现方法，可以采用最合适的技术来实现。</li><li>保持下层对上层的独立性，上层单项用下层提供的服务。</li><li>整个分层结构促进标准化工作。</li></ol><h5 id="1-2-2-分层的概念"><a href="#1-2-2-分层的概念" class="headerlink" title="1.2.2 分层的概念"></a>1.2.2 分层的概念</h5><p>分层概念的基础是“模块”的概念。一个模块可以是一个过程或一台设备，它完成一个特定的功能；若干个模块组成一个完整的系统功能。模块提供的功能通常称之为“服务”。</p><blockquote><p>采用模块概念的好处是：设计简单、可懂性好、标准化、互换性好，有大量的现存的模块可以利用。<br>模块可以通过<strong>嵌套</strong>组成更大的模块。一个高层的模块由低层模块加上一些简单模块组成。</p></blockquote><p><img src="/2020/11/01/network_notes/2.png" alt="image-20201219205646087" style="zoom:40%;"></p><h4 id="1-3-ISO-OSI-RM"><a href="#1-3-ISO-OSI-RM" class="headerlink" title="1.3 ISO OSI/RM"></a>1.3 ISO OSI/RM</h4><p><img src="/2020/11/01/network_notes/3.png" alt="image-20201221194237821" style="zoom:50%;"></p><ul><li>物理层：传输比特，传输==透明==的比特流。<ul><li>机械尺寸</li><li>电气特性（引脚）直流电：范围内高电平</li><li>功能特性</li><li>规程特性（时序）</li></ul></li><li>数据链路层：传输帧，将网络层得到的数据组装成帧，成帧、差错控制、流量控制和传输管理。<ul><li>PTP点对点，可以实现可靠传输</li><li>计时器：发送后的事件，如果超时就重传</li></ul></li><li>网络层：传输数据报，选路（进行路由）以及拥塞控制</li><li>传输层：传输单位是报文段TCP或用户数据报UDP，提供端到端之间的可靠传输</li><li>会话层：允许不同主机的各个进程之间进行会话，记录了网络上数据传输的进度<ul><li>“网络蚂蚁”——可以让断点继续传</li></ul></li><li>表示层：处理在两个通信系统内信息的表示方式，处理大小端的问题<ul><li>加密、解密、数据压缩解压</li></ul></li><li>应用层：用户与网络的界面没提供访问手段（文件传输）<ul><li>FTP、SMTP、HTTP</li></ul></li></ul><p><em>注：从会话层开始，传输的内容都是message报文</em></p><h4 id="1-4-TCP-IP-RM"><a href="#1-4-TCP-IP-RM" class="headerlink" title="1.4 TCP/IP/RM"></a>1.4 TCP/IP/RM</h4><p><img src="/2020/11/01/network_notes/4.png" alt="image-20201221200043844" style="zoom:40%;"></p><ul><li>数据链路层：<ul><li>作用：(1) 实现网卡接口的网络驱动，以处理数据在以太网线等物理媒介上的传输<br>            (2) 网络驱动程序隐藏了不同物理网络的不同电气特性，为上层协议提供一个统一的接口 </li><li>协议：ARP、RARP</li></ul></li><li>网络层：<ul><li>作用：选路、做拥塞控制、对上层协议隐藏了网络拓扑连接的细节</li><li>协议：RIP、OSPF、IP、ICMP、PGP、ARP</li></ul></li><li>传输层：<ul><li>作用：为应用程序隐藏了数据包跳转的细节，负责数据包的收发、链路超时重连</li><li>协议：TCP、UDP</li></ul></li><li>应用层：<ul><li>作用：为操作系统或网络应用程序提供访问网络服务的接口</li><li>协议：telnet、HTTP、FTP、SMTP</li></ul></li></ul><h4 id="1-5-传输时延，传播时延"><a href="#1-5-传输时延，传播时延" class="headerlink" title="1.5 传输时延，传播时延"></a>1.5 传输时延，传播时延</h4><p><strong>1、一些术语</strong></p><p>比特率：每秒传送的比特数。单位为bps（bit per second）也可表示为b/s</p><p>波特率：波特率表示每秒钟传送的码元符号的个数</p><p>码元：一个码元就是一个脉冲信号，波特率指的就是1秒能发送多少个码元，也就是1秒能发送多少个脉冲信号</p><p>带宽：带宽一词最初指的是电磁波频带的宽度，也就是==信号的最高频率与最低频率的差值==。目前，它被更广泛地借用在数字通信中，用来描述网络或线路理论上传输数据的最高速率。</p><p><em>我记得有一个带宽计算的练习题，晚上找一下！</em></p><p><strong>2、发送时延</strong></p><p>发送时延是主机或路由器发送数据帧所需要的时间，也就是从发送数据的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间。发送时延发生在机器内部的发送器中（一般是网络适配器），与传输信道的长度无关。</p><script type="math/tex; mode=display">发送时延 = 数据帧长度（b） / 信道带宽（b/s）</script><p><strong>3、传播时延</strong></p><p>传播时延是电磁波在信道中传播一定的距离需要花费的时间。</p><script type="math/tex; mode=display">传播时延 = 信道长度（m） / 电磁波在信道上的传播速率（m/s）</script><h3 id="第二章-物理层"><a href="#第二章-物理层" class="headerlink" title="第二章 物理层"></a>第二章 物理层</h3><p>主要功能：提供透明的比特流传输——“0、1”形式传递，不关心信息，只关注流本身</p><h4 id="2-1-四个特性"><a href="#2-1-四个特性" class="headerlink" title="2.1 四个特性"></a>2.1 四个特性</h4><p><strong>1、机械特性：</strong>指明接口的所有接线器形状、尺寸、引脚、排列等。</p><p><strong>2、电气特性：</strong>接口电缆各线的电压范围</p><p><strong>3、功能特性：</strong>某一个电平的意义</p><p><strong>4、规程特性：</strong>不同功能的各种可能事件出现顺序</p><h4 id="2-2-奈奎斯特定理、香农"><a href="#2-2-奈奎斯特定理、香农" class="headerlink" title="2.2 奈奎斯特定理、香农"></a>2.2 奈奎斯特定理、香农</h4><p><strong>奈奎斯特定理：</strong>在理想的==低通、无噪声、带宽有限==的信道中，极限码元传输率为2W波特。W是带宽（Hz），V是每个码元的离散的电平数目</p><script type="math/tex; mode=display">理想低通道下的极限数据传输率=2Wlog_2V\ \ (b/s)</script><p>奈定理限制了码元的传输速率，但是没有限制信息传输速率。</p><p><strong>香农定理：</strong>在==带宽受限且有高斯白噪声干扰==的情况下信道的极限数据传输率。可以不产生误差。</p><script type="math/tex; mode=display">信道的极限数据传输率=Wlog_2(1+S/N) \ (b/s)</script><p>S为信道传输信号的平均功率，N为高斯噪声功率。</p><h4 id="2-3-信道复用技术"><a href="#2-3-信道复用技术" class="headerlink" title="2.3 信道复用技术"></a>2.3 信道复用技术</h4><p>复用：一个物理线路同时传输多路的用户信号。（干线上的技术）</p><p><img src="/2020/11/01/network_notes/5.png" alt="image-20201221210432984" style="zoom:45%;"></p><center style="color:#C0C0C0;text-decoration:underline">频分复用示意图</center><p><strong>1、频分复用FDM：</strong>所有的用户在同样的时间里有不同的带宽。</p><blockquote><p>频分复用要求总频率宽度大于各个子信道频率之和，同时为了保证各子信道中所传输的信号互不干扰，应在各子信道之间设立隔离带，这样就保证了各路信号互不干扰</p></blockquote><p><strong>2、时分复用TDM：</strong>将时间划分成一段段的帧，每一个时分复用的用户在每一个帧占有特定的间隙（使用时间！=相等的时间片）==电话系统、蜂窝系统==</p><p>注意：STDM（统计时复用技术）是动态分配的</p><p><img src="/2020/11/01/network_notes/6.png" alt="image-20201221211024566" style="zoom:50%;"></p><center style="color:#C0C0C0;text-decoration:underline">时分复用</center><p><strong>3、波分复用WDM：</strong>在一根光纤上复用两路光在波信号</p><p><strong>4、码分复用CDM：</strong>又叫CDMA（不是第二章的collision detect！）每个用户在同样的事件使用同种频带。各用户挑选的不同的码型，用户之间就不发生干扰。==抗干扰强==</p><p><img src="/2020/11/01/network_notes/7.png" alt="image-20201221211847945" style="zoom:45%;"></p><center style="color:#C0C0C0;text-decoration:underline">CDMA</center><h4 id="2-4-曼彻斯特编码与差分曼彻斯特"><a href="#2-4-曼彻斯特编码与差分曼彻斯特" class="headerlink" title="2.4 曼彻斯特编码与差分曼彻斯特"></a>2.4 曼彻斯特编码与差分曼彻斯特</h4><p><img src="/2020/11/01/network_notes/8.png" alt="image-20201221212706085" style="zoom:40%;"></p><center style="color:#C0C0C0;text-decoration:underline">曼彻斯特编码</center><p><strong>曼彻斯特编码</strong>：每一位的==中间==有一跳变，位中间的跳变既作时钟信号，又作数据信号；从高到低跳变表示”1”，从低到高跳变表示”0”。</p><p><strong>差分曼彻斯特：</strong>还有一种是差分曼彻斯特编码，每位中间的跳变仅提供时钟定时，而用每位开始时有无跳变表示”0”或”1”，有跳变为”0”，无跳变为”1”。</p><p>？ppt这个图是错了吗</p><p>占空比都是50%</p><h4 id="2-5-码分计算"><a href="#2-5-码分计算" class="headerlink" title="2.5 码分计算"></a>2.5 码分计算</h4><p>==应该是CDMA==</p><h4 id="2-6-传输介质"><a href="#2-6-传输介质" class="headerlink" title="2.6 传输介质"></a>2.6 传输介质</h4><p>1、 双绞线：铜导线并排放在一起再绞合。</p><p>屏蔽双绞线STP（外面加一个用金属丝编织成的屏蔽层）/ 非屏蔽双绞线UTP</p><p>2、同轴电缆</p><p>3、光纤</p><p>4、无线传输介质</p><h3 id="第三章：数据链路层"><a href="#第三章：数据链路层" class="headerlink" title="第三章：数据链路层"></a>第三章：数据链路层</h3><blockquote><p>考纲：数据链路层，零比特插入，CRC，停止等待协议，滑动窗口，连续AQR，go back n，选择重传ARQ，HDLC，PPP</p></blockquote><p>实现点对点可靠传输</p><p>以太网：无确认的无连接服务</p><p>802.11（WIFI）：有确认的无连接服务（没有使用逻辑连接，但是每一帧都要确认）</p><h4 id="3-1-数据链路层"><a href="#3-1-数据链路层" class="headerlink" title="3.1 数据链路层"></a>3.1 数据链路层</h4><h5 id="3-1-2-成帧"><a href="#3-1-2-成帧" class="headerlink" title="3.1.2 成帧"></a>3.1.2 成帧</h5><p>数据链路层需要进行检测错误和修正错误（如果有必要）——一般其实都是重传机制。</p><blockquote><p>透明传输：指不管所传数据是什么样的比特组合，都应当能够在链路上传送。</p><p>但是如果使用了帧定界（SOH、EOT）就可能导致错误。因此需要解决！解决方案就是下面的字节填充和比特插入。</p></blockquote><p><strong>字节填充：</strong>每个标志字节前面插入特殊的转义字符ESC，只要标志字节前面没有转义字符，就可以作为帧的分界标识。当然，在传给网络层之前，ESC要被删掉。——是PPP协议的内容</p><p><img src="/2020/11/01/network_notes/9.png" alt="image-20201222005022714" style="zoom:40%;"></p><center style="color:#C0C0C0;text-decoration:underline">字节填充技术</center><p><strong>0比特填充：</strong>每个帧的开头用<code>0x7E</code>或者<code>01111110</code>表示，每当==在数据中==碰到了连续的5个1，就自动在输出比特流填一个0.——是HDLC协议的内容</p><p><em>note：这样可以确保如果接收方收到了帧，里面出现了6个1，那么一定只有可能是帧的开头而不会是数据。当然，接收方在处理的时候也要记得把5个1后面的0去掉以免影响拆帧</em></p><h5 id="3-1-3-差错控制"><a href="#3-1-3-差错控制" class="headerlink" title="3.1.3 差错控制"></a>3.1.3 差错控制</h5><p>特殊的控制帧：对接收的帧进行肯定或者否定的确认。</p><p>计时器：发出帧以后启动。如果长时间没有收到确认帧，认为失败，重传。（需要有编序号区别）</p><h5 id="3-1-4-流量控制"><a href="#3-1-4-流量控制" class="headerlink" title="3.1.4 流量控制"></a>3.1.4 流量控制</h5><p>基于反馈；基于速率。</p><h4 id="3-2-差错检测和纠正"><a href="#3-2-差错检测和纠正" class="headerlink" title="3.2 差错检测和纠正"></a>3.2 差错检测和纠正</h4><p>对于$m$个消息位和$r$个校验位，给出校验位数的下界：</p><script type="math/tex; mode=display">(m+r+1)\le 2^r</script><p><strong>奇偶校验</strong>：</p><p><strong>奇校验：</strong> 如果给定一组数据位中 1 的个数是偶数，那么奇校验位就置为 1，使得总的 1 的个数保持奇数不变。</p><p><strong>CRC：</strong></p><p>对于数据M（k位），向左边移动n位，去除以P得到商Q和余数R，余数R就作为检错码，发送时候就发{M, R}.注意，对于P的选用，是看<strong>生成多项式</strong>。例如，$P(X)=X^3+X^2+1$表示为1101.</p><script type="math/tex; mode=display">2^nM\div P=Q...R</script><p>在检查的时候，对传送过来的数据{M, R}除以P，看余数是不是0，如果是，那么检测就是对的。</p><p>CRC-32一般用于LANs。</p><h4 id="3-3-停止等待协议"><a href="#3-3-停止等待协议" class="headerlink" title="3.3 停止等待协议"></a>3.3 停止等待协议</h4><p>物理层进程和某些数据链路层进程运行在一个网络接口卡（NIC）上。</p><p>stop-and-wait：由于出现丢包（传输的数据包丢失，在数据链路层，就是帧的缺失问题）发送一帧，等待对方确认到达后才能继续发送。</p><p>==简单但是信道利用率低==</p><p><img src="/2020/11/01/network_notes/10.png" alt="image-20201222101209816" style="zoom:50%;"></p><p>差错情况：</p><p><strong>1、检测到帧出错</strong></p><p>RTT：往返传播时延，超时计时器设置的重传时间比帧传输平均RTT长。</p><p><img src="/2020/11/01/network_notes/11.png" alt="image-20201222100655211" style="zoom:50%;"></p><ul><li>发送完一个帧以后保留副本直到收到ACK。</li><li>数据帧和确认帧需要编号。</li></ul><p><strong>2、确认帧丢失</strong></p><p><img src="/2020/11/01/network_notes/12.png" alt="image-20201222100915744" style="zoom:50%;"></p><p><strong>3、ACK迟到</strong></p><p><img src="/2020/11/01/network_notes/13.png" alt="image-20201222101008414" style="zoom:50%;"></p><p>ARQ：自动重复请求。发送方在准备下一个数据项目之前先等待一个肯定的确认。传统自动重传请求分成为三种，即停等式(stop-and-wait）ARQ，回退n帧（go-back-n）ARQ，以及选择性重传（selective repeat）ARQ。后两种协议是滑动窗口技术与请求重发技术的结合，由于窗口尺寸开到足够大时，帧在线路上可以连续地流动，因此又称其为连续ARQ协议。三者的区别在于对于出错的数据报文的处理机制不同。三种ARQ协议中，复杂性递增，效率也递增。</p><h4 id="3-4-滑动窗口协议"><a href="#3-4-滑动窗口协议" class="headerlink" title="3.4 滑动窗口协议"></a>3.4 滑动窗口协议</h4><h5 id="3-4-1-GO-BACK-N"><a href="#3-4-1-GO-BACK-N" class="headerlink" title="3.4.1 GO BACK N"></a>3.4.1 GO BACK N</h5><p>发送方必响应的三件事：</p><ol><li>上层的调用；</li><li>收到ACK；——采用了<strong>累计确认</strong>的方式，表明已经接受到第N个帧以及其前面所有的</li><li>超时事件：发生超时，发送方是发送所有传输过去但是没有被确认的帧</li></ol><p>窗口长度问题：</p><p>如果采用n个比特对帧编号，发送窗口的尺寸$W_t$应满足$1\le W_t\le 2^n-1$.发送尺寸过大，就不能区分新和旧的帧。</p><blockquote><p>理解窗口问题：<a href="https://blog.csdn.net/mr_j0304/article/details/89599086（笑死）">https://blog.csdn.net/mr_j0304/article/details/89599086（笑死）</a></p></blockquote><p>pros：连续发送提高了信道利用率</p><p>cons：重传是必须把可能是正确传送的内容重传，效率低了</p><h5 id="3-4-2-选择重传SP"><a href="#3-4-2-选择重传SP" class="headerlink" title="3.4.2 选择重传SP"></a>3.4.2 选择重传SP</h5><p>发送方必响应的三件事:</p><ol><li>上层的调用；</li><li>收到了一个ACK；#如果是下界，就滑动窗口；</li><li>每个帧都有自己的定时器</li></ol><p>接收方要做的事：</p><ol><li>来者不拒，滑动窗口</li><li>如果收到了窗口序号外的帧（说明自己发的ack丢了）那么再发一个ACK</li></ol><p>窗口长度问题：</p><p>发送窗口等于接收窗口。——发送过大导致不能接收。最好是$W_s=W_r=2^{(n-1)}$</p><h4 id="3-5-点对点协议PPP"><a href="#3-5-点对点协议PPP" class="headerlink" title="3.5 点对点协议PPP"></a>3.5 点对点协议PPP</h4><p>只支持全双工链路，面向字节的协议。</p><p>满足的要求：简单、封装成帧、透明传输(==异步线路：使用字节填充/同步线路：用比特填充==)、多种网络层协议、多种链路类型、差错检测、检测连接状态、MTU（&lt;=1500）、网络层地址协商。</p><p>LCP：建立物理连接，通信的双方可以协商一些选项</p><p>NCP：建立逻辑连接</p><h4 id="3-6-高级数据链路控制HDLC"><a href="#3-6-高级数据链路控制HDLC" class="headerlink" title="3.6 高级数据链路控制HDLC"></a>3.6 高级数据链路控制HDLC</h4><p>使用0比特插入法实现透明传输。只支持全双工链路。</p><p>信息帧、监督帧、无编号帧。</p><p><strong>对比</strong>：</p><p><img src="/2020/11/01/network_notes/14.png" alt="image-20201222145337196" style="zoom:60%;"></p><h3 id="第四章：介质访问控制子层"><a href="#第四章：介质访问控制子层" class="headerlink" title="第四章：介质访问控制子层"></a>第四章：介质访问控制子层</h3><blockquote><p> ALOHA，CSMA，CSMA/CD，CSMA/CA，RTS/CTS，隐蔽站，暴露站，IEEE 802体系结构，MAC Address，Ethernet MAC Frame，最短帧长，互连设备，网桥/交换机的工作原理，VLAN，802.11 WLAN</p></blockquote><h4 id="4-1-ALOHA"><a href="#4-1-ALOHA" class="headerlink" title="4.1 ALOHA"></a>4.1 ALOHA</h4><ul><li>两个版本：纯ALOHA/ 分槽ALOHA</li><li>基本思想：当有用户数据需要发送的时候就传输</li><li><strong>竞争</strong>：系统中多个用户共享一个信道的方法会导致冲突</li></ul><h5 id="4-1-1-纯ALOHA"><a href="#4-1-1-纯ALOHA" class="headerlink" title="4.1.1 纯ALOHA"></a>4.1.1 纯ALOHA</h5><ol><li>生成帧以后就发送（任意时间，不关心信道是否被使用）;</li><li>检测信道，判断是否成功;</li><li>如果冲突，失败，等随机事件后重发;</li><li>vulnerable time = 2T;</li><li>吞吐量S=$GP_0$;</li><li>最好的信道利用率为$1/2e$.</li></ol><p><img src="/2020/11/01/network_notes/15.png" alt="image-20201222160239706" style="zoom:25%;"></p><h5 id="4-1-2-分槽ALOHA"><a href="#4-1-2-分槽ALOHA" class="headerlink" title="4.1.2 分槽ALOHA"></a>4.1.2 分槽ALOHA</h5><ol><li>把时间分成时间片，时间间隔=帧时T；</li><li>发送帧在间隔的起点，因此冲突只发生在开头；</li><li>vulnerable time = T</li><li>一旦某个站点占用时间槽并IQ而发送成功，该槽内无冲突；</li><li>最好的信道利用率为$1/e$.</li></ol><p><img src="/2020/11/01/network_notes/16.png" alt="image-20201222163535202" style="zoom:50%;"></p><h4 id="4-2-载波侦听多路协议CSMA"><a href="#4-2-载波侦听多路协议CSMA" class="headerlink" title="4.2 载波侦听多路协议CSMA"></a>4.2 载波侦听多路协议CSMA</h4><p>Carrier Sense Multiple Access——站可以检测其他的站在做什么，再调整自己的行为。</p><p>CSMA can reduce the possibility of collision, but can’t eliminate it.</p><h5 id="4-2-1-坚持和非坚持CSMA"><a href="#4-2-1-坚持和非坚持CSMA" class="headerlink" title="4.2.1 坚持和非坚持CSMA"></a>4.2.1 坚持和非坚持CSMA</h5><p><strong>1. 一坚持</strong></p><ul><li>侦听—&gt;信道空闲—&gt;发送</li><li>侦听—&gt;信道忙—&gt;侦听直到听到空闲—&gt;发送</li></ul><p><strong>2. 非坚持</strong>（延迟大）</p><ul><li>侦听—&gt;信道空闲—&gt;发送</li><li>侦听—&gt;信道忙—&gt;等待随机时间后发送（不监听，就看看过段时间空了没）</li></ul><p><strong>3. p坚持</strong></p><ul><li>侦听—&gt;信道空闲—&gt;以p的概率发送—-</li></ul><h5 id="4-2-2-CSMA-CD"><a href="#4-2-2-CSMA-CD" class="headerlink" title="4.2.2 CSMA/ CD"></a>4.2.2 CSMA/ CD</h5><p>带冲突检测的载波侦听协议——“先听后发，边发边听”，以太网的基础。只能是半双工</p><p><img src="/2020/11/01/network_notes/17.png" alt="image-20201222163509772"></p><h4 id="4-3-无冲突协议"><a href="#4-3-无冲突协议" class="headerlink" title="4.3 无冲突协议"></a>4.3 无冲突协议</h4><p><strong>1、位图协议</strong>：在实际传送之前先广播自己有发送的需求到竞争槽</p><p>​                                                                                                                                                                                                                </p><h4 id="4-4-隐蔽站和暴露站问题"><a href="#4-4-隐蔽站和暴露站问题" class="headerlink" title="4.4 隐蔽站和暴露站问题"></a>4.4 隐蔽站和暴露站问题</h4><p><strong>隐蔽站</strong>：由于竞争者离得太远而导致无法检测到潜在的竞争者。比如A给B发数据，但是C载波侦听的时候听不到A（太远了）所以以为自己给B阿发不会有问题，就发送给B，然后在B处发生冲突。</p><p><img src="/2020/11/01/network_notes/18.png" alt="image-20201222165220070" style="zoom:40%;"></p><center style="color:#C0C0C0;text-decoration:underline">隐蔽站问题</center><p><strong>暴露站</strong>：非竞争者隔得太近，暴露给对方导致对方以为有冲突。B向A传，C想给D传，结果C真听到传输进行，以为不能向D传。</p><p><img src="/2020/11/01/network_notes/19.png" alt="image-20201222165610082" style="zoom:35%;"></p><p><strong>解决方案：MACA</strong></p><p>MACA：冲突避免多路访问，可以代替CSMA。</p><p>技术：</p><ol><li><p>想要发送，给接收方发一个RTS（包含数据长度）；</p><pre><code>          2. 对方同意，返回一个CTS（包含数据长度）；                  3. 收到CTS，开始传输。                    4. 侦听到RTS，说明离发送方近，保持沉默直到CTS回来；帧听到CTS，说明离接收方近，保持沉默直到帧传完。</code></pre></li></ol><h4 id="4-5-IEEE-802标准"><a href="#4-5-IEEE-802标准" class="headerlink" title="4.5 IEEE 802标准"></a>4.5 IEEE 802标准</h4><p>IEEE 802将OSI的数据链路层分为两个子层，分别是逻辑链路控制(Logical Link Control, LLC)和介质访问控制(Media Access Control, MAC)</p><p><img src="/2020/11/01/network_notes/20.png" alt="image-20201222171431465"></p><p><strong>二进制指数后退算法：</strong></p><p>CSMA/CA </p><p>在第i次冲突后，从$0\to2^i-1$中间随机选一个数。达到十次冲突以后，随机数的选择区间被固定在1023不再增加，16次冲突以后发送失败报告。</p><h4 id="4-7-互联设备"><a href="#4-7-互联设备" class="headerlink" title="4.7 互联设备"></a>4.7 互联设备</h4><p><strong>1、网桥</strong>（不涉及网络层）</p><p>先检查此帧的目的MAC地址，然后再确定将该帧转发在哪个接口或者丢弃。转发和过滤</p><p>优点：</p><ol><li>过滤通信量，增大吞吐量；</li><li>提高了可靠性；</li><li>可以互联不同的物理层、MAC和不同速率的以太网。</li></ol><p>==如果把三个网段用网桥连接起来，那么吞吐量为三者之和（如果使用物理层设备，那就是还是员来的吞吐量）== </p><p>透明网桥：以太网的站点不知道发送的帧将经过哪几个网桥。</p><p>透明网桥在做自学习的时候，写是写原地址的信息，读是读目的地址的信息。转发表是会被删除的！为了保持最新状态。</p><p>原路由网桥： 向要通信的发送发现帧</p><p><strong>2、交换机</strong></p><p><img src="/2020/11/01/network_notes/21.png" alt="image-20201222201307988" style="zoom:50%;"></p><p>可以独占传输媒体带宽：可以占用交换机的总带宽。</p><p>直通式交换机：查找MAC地址，时延小，但是不检错，速率不同的端口不可以交换</p><p>存储转发：放入高速缓存。</p><div class="table-container"><table><thead><tr><th>设备</th><th>能否隔离冲突域</th><th>能否隔离广播域</th></tr></thead><tbody><tr><td>物理层设备（中继器、集线器）</td><td>x</td><td>x</td></tr><tr><td>链路层设备（网桥、交换机）</td><td>v</td><td>x</td></tr><tr><td>网络层设备（路由器）</td><td>v</td><td>v</td></tr></tbody></table></div><blockquote><p>广播域：指的是广播帧(目标MAC地址全部为1)所能传递到的范围，亦即能够直接通信的范围。</p><ul><li>交换机能缩小冲突域的范围，交换接的每一个端口就是一个冲突域；</li><li>路由器默认也是可以隔离冲突域的。</li></ul><p>冲突域：就是同一时间内只能有一台设备发送信息的范围。</p><ul><li>第三层设备能隔离广播域，比如Router。路由器能隔离广播域，其每一个端口就是一个广播域；</li><li>数据链路层的VLAN也能隔离广播域。</li></ul></blockquote><h4 id="4-8-IEEE-802-11无线局域网"><a href="#4-8-IEEE-802-11无线局域网" class="headerlink" title="4.8 IEEE 802.11无线局域网"></a>4.8 IEEE 802.11无线局域网</h4><p>无线局域网 &gt; WIFI （Aeria）</p><p><img src="/2020/11/01/network_notes/22.png" alt="image-20201222210913007" style="zoom:33%;"></p><p>地址1~4：接收端、发送端、目的地址、原地址</p><h4 id="4-9-VLAN"><a href="#4-9-VLAN" class="headerlink" title="4.9 VLAN"></a>4.9 VLAN</h4><p>VLAN通过限制广播帧转发的范围分割了广播域。更为直观地描述VLAN的话，我们可以把它理解为将一台交换机在逻辑上分割成了数台交换机。</p><h3 id="第五章：网络层"><a href="#第五章：网络层" class="headerlink" title="第五章：网络层"></a>第五章：网络层</h3><blockquote><p>考纲要求：数据报与虚电路，路由算法：DV向量/LSP，拥塞控制，==QoS==，路由器IP协议，IP分类地址、子网划分、超网、CIDR（地址聚集，路由最长匹配），==NAT==，==IPv6==，ICMP，ARP，RIP，==OSPF,  BGP==</p></blockquote><h4 id="5-1-设计问题"><a href="#5-1-设计问题" class="headerlink" title="5.1 设计问题"></a>5.1 设计问题</h4><p>1、 存储转发数据包交换：数据包到达路由器以后，先被存储在路由器上，然后沿着路径转发到下一个路由器，直达目标主机。</p><p>2、服务：将源端产生 的数据包发送到目的机。</p><ul><li>封装；</li><li>寻找目的机；</li><li>选路；</li></ul><p>3、提供给传输层的服务：</p><ul><li>向上提供的服务独立于路由器技术；</li><li>向传输层屏蔽路由器的数量、类型和拓扑关系；</li><li>传输层的网络地址有统一编址方案，可以跨越LAN和WAN。</li></ul><p>4、无连接服务：<strong>数据报datagram</strong></p><p>数据报网络：</p><p><img src="/2020/11/01/network_notes/23.png" alt="image-20201217093208333" style="zoom:30%;"></p><p>表项：目标地址、通往目标地址所使用的出境线路。（当发生流量拥塞等时，更新路由表）</p><p><em>注意：F只是一个Router，当数据包到达了F以后，被封装成一个帧通过连接了H2的LAN被发送到H2。</em></p><p>5、面向连接的服务：</p><p>当建立连接时，source到destination的路径就被当做这个链接的一部分被确定了下来，保存在中间路由器的表中。<strong>MPLS</strong>多协议标记交换</p><p>面向连接：<strong>虚电路Virtual Circuit</strong></p><div class="table-container"><table><thead><tr><th>比较</th><th>数据报子网</th><th>虚电路子网</th></tr></thead><tbody><tr><td>电路</td><td>不一定要建立电路</td><td>一定要建立电路</td></tr><tr><td>分组</td><td>包含完整的源地址、目的地之的信息，独立寻址</td><td>只包括一个短的VC编号</td></tr><tr><td>路由</td><td>不需要保留连接状态</td><td>需要保留连接状态</td></tr><tr><td>路由器失效影响</td><td>基本没有影响</td><td>连接中断</td></tr><tr><td>服务质量拥塞控制</td><td>很难实现</td><td>容易实现</td></tr></tbody></table></div><p><img src="/2020/11/01/network_notes/24.png" alt="image-20201217095137211" style="zoom:30%;"></p><h4 id="5-2-路由算法"><a href="#5-2-路由算法" class="headerlink" title="5.2 路由算法"></a>5.2 路由算法</h4><p>负责确定一个入境数据包应该发送到那一条输出线路上。</p><blockquote><p>路由器内两个进程：</p><ul><li>对数据包进行处理，查找对应的出境路径（forward）</li><li>负责生成和更新路由表（apply to 路由算法）</li></ul></blockquote><p><em>正确性、简单性、鲁棒性、稳定性、公平性、有效性</em></p><p>静态路由（自适应算法）：改变路由政策，以反映出拓扑结构的变化</p><div class="table-container"><table><thead><tr><th>路由模式</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>静态</td><td>安全，总是通过同一路径到达（稳定），小网络中容易实施，不需要cpu等</td><td>仅适用于简单网络；网络增大， 配置变复杂；需要人工的更新和维护</td></tr><tr><td>动态</td><td>适用于有多个路由器的网络，不受到规模的限制。而且可以自动更新和维护路由信息</td><td>实施复杂， 有安全隐患，而且需要CPU等来维护</td></tr></tbody></table></div><h5 id="5-2-1-优化原则"><a href="#5-2-1-优化原则" class="headerlink" title="5.2.1 优化原则"></a>5.2.1 优化原则</h5><p>优化直接结果：所有的源到一个制定目标的最优路径集合构成了以source为根节点的树（<strong>汇集树</strong>）形成了DAG。</p><h5 id="5-2-2-最短路径算法"><a href="#5-2-2-最短路径算法" class="headerlink" title="5.2.2 最短路径算法"></a>5.2.2 最短路径算法</h5><p>即Dijkstra算法</p><h5 id="5-2-3-泛洪算法flooding"><a href="#5-2-3-泛洪算法flooding" class="headerlink" title="5.2.3 泛洪算法flooding"></a>5.2.3 泛洪算法flooding</h5><p>该技术将每一个入境数据包发送到除了该数据包到达的线路以外的出境路线。</p><p>问题：传输产生重复数据包</p><p>解决：</p><ol><li><p>每个数据包的头设置一个跳计数器</p><pre><code>            2. 路由器跟踪数据包</code></pre></li></ol><p>泛洪可以并发选择每一条可能的路径，因此也可以找到最短的一条。该算法鲁棒性好。缺点是开销大，造成了浪费。</p><h5 id="5-2-4-距离矢量算法（distance-vector-routing）"><a href="#5-2-4-距离矢量算法（distance-vector-routing）" class="headerlink" title="5.2.4 距离矢量算法（distance vector routing）"></a>5.2.4 距离矢量算法（distance vector routing）</h5><p><strong>RIP协议</strong>：RIP协议基于距离矢量算法（DistanceVectorAlgorithms），使用“跳数”(即metric)来衡量到达目标地址的路由距离。这种协议的路由器只关心自己周围的世界，只与自己相邻的路由器交换信息，范围限制在15跳(15度)之内，再远，它就不关心了。</p><p>DV是分布式bellman-ford路由算法，用于小型网络。工作原理：</p><ol><li>每个节点维护路由表，包含首选的出境路线以及距离估计值（量度可能是跳数）；</li><li>和自己的邻居交换路由信息；</li><li>根据接收到的交换矢量信息，更新自己的路由表。</li></ol><p>缺点：</p><ol><li>交换的信息太大了（邻居的路由表都要接收）不适合大型的网路</li><li>路由信息传播的慢</li><li>路由器的信息认识不一致，可能使用不同的拓扑结构</li><li>收敛慢*（导致无穷计算问题）</li></ol><p><strong>无穷计算问题</strong>：好消息传播快，坏消息传播慢。</p><p><img src="/2020/11/01/network_notes/25.png" alt="image-20201217110002667" style="zoom:60%;"></p><h5 id="5-2-5-链路状态路由"><a href="#5-2-5-链路状态路由" class="headerlink" title="5.2.5 链路状态路由"></a>5.2.5 链路状态路由</h5><p>步骤：</p><ol><li><p><strong>发现</strong>它的邻居节点，并了解网络地址；</p><p>点到点的线路发送hello报文——收者应答（with自己==全局唯一==的名字）</p><p>多个路由器通过广播链路连接（比如交换机、环、以太网等）让他们之间传递hello</p></li><li><p><strong>设置</strong>到每个邻居节点的距离或者成本度量；</p><p>常见：使用链路带宽、延迟。</p><p>发送一个ECHO，另一端立刻应答——测量往返时间RTT，得到合理估计</p></li><li><p><strong>构造</strong>一个包所有刚知道的链路信息包；Link State Packets（LSPs）</p><p>数据包内容：发送方的标识符，序号，年龄，邻居列表，到邻居的成本</p></li><li><p><strong>发送</strong>到其他路由器，并接受其他的信息包；</p><p>算法：</p><p>​    使用泛洪的方法（每个数据包都包含了序号，序号递增，从而控制泛洪的规模）</p><p>​    路由器记录它看见的所有&lt;原路由器，序号&gt;</p><p>​        —-&gt; 新数据包：广播</p><pre><code>    ---&gt; 重复数据包：丢弃</code></pre><p>​        —-&gt; 过时（序号小于最大）：拒绝</p><p>问题：</p><p>​    (1) 序号绕回：使用32位</p><p>​    (2) 路由器崩溃，数据丢失</p><p>​    (3) 序列号破坏，传输出错</p><p>解决方案：</p><p>age—；当age==0，当前LSP被丢弃</p><p>注意，所有的链路状态要求被确认，从而防止线路故障。</p><p>下图是路由器B的状态包缓冲区，必须要得到确认，才能从缓冲放到路由器中进行使用。</p><p><img src="/2020/11/01/network_notes/26.png" alt="image-20201217114802386"></p><center style="color:#C0C0C0;text-decoration:underline">link state缓冲示意图</center></li><li><p><strong>计算</strong>最短路径。</p><p>使用的是最短路径算法</p></li></ol><h5 id="5-2-6-层次路由"><a href="#5-2-6-层次路由" class="headerlink" title="5.2.6 层次路由"></a>5.2.6 层次路由</h5><p>分层路由：路由器被划分成区域（Region）。每个路由器知道如何把数据包路放到自己所在的区域内的目标地址，但对于其他地址不知情。</p><p>发现：对于包含了N个路由器的网络，最优的层数是$ln N$</p><h5 id="5-2-7-广播路由"><a href="#5-2-7-广播路由" class="headerlink" title="5.2.7 广播路由"></a>5.2.7 广播路由</h5><p>1、受控制的泛洪：使用<strong>逆向路径转发</strong>，如果一台路由器接收到一个分组的时候，需要做一件事情，查看一下分组的源地址，检查这个分组是否是从源结点到此结点的最短路径上。如果是的话，就进行继续转发，如果不是，则直接丢弃分组。</p><p>2、生成树广播：需要定义一个中心结点，然后其他结点都向中心结点单播“加入树报文”，如果路径还未在树中，那么就直接加入树，如果路径中的某些部分已经在树中，例如该路径是B -&gt; A -&gt; F -&gt; C -&gt; G，但是F已经在树中了，那么就将B -&gt; A加入到树中。通过这样的方法创建一颗生成树。            </p><p><img src="/2020/11/01/network_notes/27.png" alt="image-20201217140854787" style="zoom:33%;"></p><center style="color:#C0C0C0;text-decoration:underline">生成树广播机制</center><p>==这个spanning tree怎么生成==</p><p><em>note：后面还有几种，这里不一一列举讲了</em></p><h4 id="5-3-拥塞控制算法"><a href="#5-3-拥塞控制算法" class="headerlink" title="5.3 拥塞控制算法"></a>5.3 拥塞控制算法</h4><p>congestion：某一部分资源超过了处理的能力，没有缓冲区，处理拥塞是网络层和运输层共同的责任。</p><h5 id="5-3-1-解决的基本途径"><a href="#5-3-1-解决的基本途径" class="headerlink" title="5.3.1 解决的基本途径"></a>5.3.1 解决的基本途径</h5><ol><li>increase the resource 扩容</li><li>decrease the load 减少负载</li></ol><p>Pretentative                                                                     reactive</p><p>​    &lt;—————————————————————————————————————&gt;</p><p>​             provision  routing  control throttling shedding </p><ul><li><p>流量感知路由：用一些指标对路径加权，权值最小的负载最轻</p></li><li><p>准入控制：在建立新的虚电路之前就控制，如果会造成拥塞，就不让其被建立</p><ul><li><strong>早期随机检测（RED）</strong>：路由器维护一个运行队列长度的平均值，当长度超过了阈值，该链路被认为将要拥塞，就随机丢弃一小部分数据包。</li></ul></li><li><p>流量调节：被拥塞的路由器发出信号要求slow down。</p><ul><li><p>ECN显式拥塞通知：在双向通信的基础上，实现反馈，将带有mark的packet送回到Host machine，告知其目标路由器（即发出消息的路由器）路径上有拥塞</p><p>（这一功能通过ack捎带带回原来的路径）</p></li></ul></li><li><p>负载脱落：</p><ul><li>随机丢弃（RED）在拥塞==有苗头==的时候就随机丢弃数据包</li><li>丢弃新到达的：适合于文件传输类</li><li>丢弃早到的分组：适用于多媒体类</li><li>丢弃不太重要的分组：需要提前指明优先级</li></ul></li></ul><h4 id="5-4-服务质量"><a href="#5-4-服务质量" class="headerlink" title="5.4 服务质量"></a>5.4 服务质量</h4><p><em>对应PPT P67， 书312，这好像是我掉的那节课讲的</em> :sweat_smile:</p><h5 id="5-4-2-流量整形"><a href="#5-4-2-流量整形" class="headerlink" title="5.4.2 流量整形"></a>5.4.2 流量整形</h5><p>算法：令牌桶、漏桶</p><p>目标：发送适合他们需求的各种各样流量</p><p><img src="/2020/11/01/network_notes/28.png" alt="image-20201217150229736" style="zoom:33%;"></p><ul><li>当满时，漏桶的分组被丢弃，而令牌桶丢掉令牌而不是分组；</li><li>令牌桶允许突发，但最大突发受限于令牌桶大小，漏桶不可以；</li><li><img src="/2020/11/01/network_notes/29.png" alt="image-20201217150759832" style="zoom:50%;"></li></ul><h4 id="5-5-网际互联"><a href="#5-5-网际互联" class="headerlink" title="5.5 网际互联"></a>5.5 网际互联</h4><p><em>PPT p78， 书p326</em></p><p>网桥主要用来连接链路层的同类网络，而路由器用来连接网络层不同的网络。</p><p>1、<strong>隧道技术</strong></p><p>connect two networks through a middle one. 比如说两个IPv4的网络中间隔了一个IPv6，那么就在传输的时候把一个IPv4的内容用IPv6封装起来，整个IPv4的datagram成为了IPv6的payload部分。</p><p>2、<strong>数据包分段 packet fragmentation</strong></p><p>因为某些原因（书p332），要求限制数据包的最大长度。通用的IP协议运行的数据包长度最大为65515字节。有一种方法：设置<strong>MTU</strong>（最大传输单元）</p><p>允许路由器将数据包拆分成段，将每一个段作为一个独立的网络层数据包进行发送。</p><p>透明分片：先在路由器中被分割成多段，再发到同一个出口路由器，被重新组合起来</p><p>非透明分片：到了目标主机才会充足，也就是交付的时候才交完整内容。此方法路由器所做的工作比较少，IP就是这种方式</p><p>ref: <a href="https://blog.csdn.net/hanzhen7541/article/details/79031781">https://blog.csdn.net/hanzhen7541/article/details/79031781</a></p><p>路径MTU发现：这个策略是为了避免了传到下一个路由器因为太大而要做分片。当传输到某一个路由器的时候，如果大小已经超过了其所能传输的最大量，发送一个信号回去给source router，并且当前数据包被丢弃。</p><p><img src="/2020/11/01/network_notes/30.png" alt="路径MTU发现"></p><center style="color:#C0C0C0;text-decoration:underline">路径MTU发现示意图</center><h4 id="5-6-Internet的网络层"><a href="#5-6-Internet的网络层" class="headerlink" title="5.6 Internet的网络层"></a>5.6 Internet的网络层</h4><h5 id="5-6-1-IPv4协议"><a href="#5-6-1-IPv4协议" class="headerlink" title="5.6.1 IPv4协议"></a>5.6.1 IPv4协议</h5><p><img src="/2020/11/01/network_notes/31.png" alt="image-20201217203234506" style="zoom:33%;"></p><p>version—版本号，目前经常使用的是第四版本，所以version的值一般为4；</p><p>IHL—header length，注意此length是32位字长，因此最短为5，最长为15（options can be 10 more）；</p><p>service：现在前6位一般用于标记数据包的服务类别， 后2位用来携带显式的拥塞控制。</p><p>totlengh：总长度</p><p>protocol：UDP（17）TCP（6）</p><p><em>第二行全部是用来做分片问题的，id是为了区分65535个不同的包，DF是don’t fragment,当DF==1时，表示不愿意做分片，因此大于了当前路由器所处理的能力时，就会丢弃这个数据包，并向source发送此信息，从而让他自己切了重新发。MF是如果DF\==0的情况下，表示了当前的片后面是否还有，也就是表示当前的碎片是不是最后一个。最后的frag offset就是表示了块偏移量的问题。</em></p><p>ttl：time to leave，还有多长时间离开这个网络，避免了数据包永远留在网络里。一般设置为255.</p><p>protocol：tcp 或者 udp</p><h5 id="5-6-2-IP-地址"><a href="#5-6-2-IP-地址" class="headerlink" title="5.6.2 IP 地址"></a>5.6.2 IP 地址</h5><p>IP地址是点分十进制：xxxxxxxx.xxxxxxxx.xxxxxxxx.xxxxxxxx</p><p><strong>网络的层次化设计：</strong></p><p><img src="/2020/11/01/network_notes/32.png" alt="image-20201218133934287" style="zoom:30%;"></p><p>1． A类IP地址 </p><p>一个A类IP地址由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”， 地址范围从==1.0.0.0 到126.0.0.0==。可用的A类网络有126个，每个网络能容纳$2^{24}-2$个主机。 </p><p>2． B类IP地址 </p><p>一个B类IP地址由2个字节的网络地址和2个字节的主机地址组成，网络地址的最高位必须是“10”，地址范围从128.0.0.0到191.255.255.255。可用的B类网络有16382个，每个网络能容纳$2^{16}-2$个主机 。 </p><p>3． C类IP地址 </p><p>一个C类IP地址由3字节的网络地址和1字节的主机地址组成，网络地址的最高位必须是“110”。范围从192.0.0.0到223.255.255.255。C类网络可达209万余个，每个网络能容纳254个主机。 </p><p><strong>前缀：</strong>IP地址具有层次结构，一个网络对应一块连续的IP地址空间，这个地址空间就是地址的前缀。由于前缀的长度并不能通过IP地址推断，因此引入<strong>子网掩码</strong>。</p><p><strong>子网：</strong>在内部将一个网络块分成几个部分供多个内部网络使用，但是对外部仍然像是单个网络。</p><p>subnetting splits up IP prefix to help with management</p><p><em>这里关于划分和聚合的问题就直接后面做题</em></p><p><strong>CIDR——无类域间路由</strong>：分成不同的网络，但是这些不同的网络并没有类型区分。CIDR与层次化设计不同之处在于，CIDR的地址块大小不是固定的。</p><p><strong>NAT——网络地址转换：</strong>在主机不活跃的时候收回分配给他的IP地址。每一个主机在网络内部有一个IP地址，在传输数据的时候要把内’的IP地址转换为共享的公共IP地址</p><p>为了达成公用IP与网络内私有IP的转换，NAT转换器完成转换，并且维护一个地址转换表。</p><h5 id="5-6-3-IPv6协议"><a href="#5-6-3-IPv6协议" class="headerlink" title="5.6.3 IPv6协议"></a>5.6.3 IPv6协议</h5><p>IPV4没有anycast，也有multicast、unicast，但这些IPv6都有。</p><h5 id="5-6-4-Internet-控制协议"><a href="#5-6-4-Internet-控制协议" class="headerlink" title="5.6.4 Internet 控制协议"></a>5.6.4 Internet 控制协议</h5><p>上面所说的IP协议都是用来做数据传输的。在网络层除此之外，还有几个辅助的控制协议。</p><p><strong>ICMP：Internet 控制消息协议</strong></p><p>（1）功能：项数据包的源端报告差错事件；测试网络（如ping）。</p><p>（2）消息类型：包括目的地不可达、超时、参数问题、源抑制、重定向、回显、请求时间戳、路由器通告等。详细的消息类型及其使用见书P358.</p><p>（3）应用：</p><ul><li>Ping：原机向目标发出ICMP 的请求报文，站点收到则必须回复。可以通过ping的结果反映TCP/IP是否正常、网络设备是否正常，还可以检查对外链接的路由器、检查DNS。</li><li>路径的MTU：可以检测所能传输的最大长度。</li><li>注意：ICMP只能发给source，不能生成自己的差错报告（不得递归使用）。</li></ul><p><strong>ARP：地址解析协议</strong></p><p>（1）原理：知道目标地址的IP地址求目标地址的MAC地址，做法是广播一个ARP请求，只有目标主机应答，并且回复自己的mac地址。（所以，ARP的请求帧里面的目的地址是全1）</p><p>（2）优化：</p><ul><li>建立一个ARP表缓存结果（掉电会丢失）；</li><li>用ARP请求中的原信息来更新表；</li><li>每台机器启动时广播IP/MAC地址时，可以主动报告自己的信息（如果有任何自己一样，就会收到应答）；</li><li>广播的时候，所有主机都能收到当前源的IP地址；</li><li>周期性删除过时的信息。</li></ul><p>（3）安全隐患：ARP病毒</p><p><strong>OSPF：内部网关路由协议</strong></p><p>（1）术语：</p><ul><li>Router ID：32位，自治系统内唯一；</li><li>协议号：89，直接封装在报文中；</li><li>TTL=1，通常OSPF值传给邻居的路由器。</li></ul><p>（2）技术：</p><ul><li><p>OSPF 中划分区域的目的就是在于控制链路状态信息LSA 泛洪的范围、减小链路状态数据库LSDB的大小、改善网络的可扩展性、达到快速地收敛。</p></li><li><p>当设计 OSPF 网络时，一个很好的方法就是从骨干区域开始，然后再扩展到其他区域。骨干区域在所有其他区域的中心，即所有区域都必须与骨干区域物理或逻辑上相连，这种设计思想的原因是 OSPF 协议要把所有区域的路由信息引入骨干区，然后再依次将路由信息从骨干区域分发到其它区域中。</p></li><li>backbone ID：not IP addr</li><li><p><img src="/2020/11/01/network_notes/33.png" alt="image-20201218172353257"></p></li><li><p>支持了安全性（因为要鉴别发送人身份）</p></li><li>作为一种链路状态的路由协议，OSPF将链路状态组播数据LSA（Link State Advertisement）传送给在某一区域内的所有路由器，这一点与距离矢量路由协议不同。运行距离矢量路由协议的路由器是将部分或全部的路由表传递给与其相邻的路由器。</li></ul><p><strong>BGP：外部网关路由协议</strong></p><p><img src="/2020/11/01/network_notes/34.png" alt="image-20201223002433260"></p><h3 id="第六章：运输层"><a href="#第六章：运输层" class="headerlink" title="第六章：运输层"></a>第六章：运输层</h3><blockquote><p>考纲要求： 端口，套接字，UDP及其伪首部，TCP连接建立与释放，TCP可靠传输，TCP流控机制，TCP拥塞控制：慢启动、拥塞避免、快恢复，Socket，C/S架构</p></blockquote><p>运输层为相互通信的应用进程提供了逻辑通信。“逻辑通信”的意思是：运输层之间的通信好像是沿水平方向传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。</p><p>运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道。</p><h4 id="6-1-端口号"><a href="#6-1-端口号" class="headerlink" title="6.1 端口号"></a>6.1 端口号</h4><p>解决不需要知道实现这个功能的进程的问题。虽然通信的终点是应用进程，但我们可以把端口想象是通信的终点，因为我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付目的进程）就由 TCP 来完成。</p><ul><li>范围：0 至 65535 （$2^{16}$)；</li><li>端口号只具有本地意义，在因特网中不同计算机的相同端口号是没有联系的；</li><li>三类端口：熟知端口 / 登记端口号 / 客户端口号</li></ul><h4 id="6-4-Internet-传输协议：UDP"><a href="#6-4-Internet-传输协议：UDP" class="headerlink" title="6.4 Internet 传输协议：UDP"></a>6.4 Internet 传输协议：UDP</h4><ul><li>UDP 只在 IP 的数据报服务之上增加了端口的功能和差错检测的功能；</li><li>无连接：发送前不建立连接；</li><li>尽最大努力交付，没有拥塞控制；</li><li><p>支持一对一、一对多、多对一和多对多；</p></li><li><p>面向报文：添加首部后就向下交付 IP ，不合并，也不拆分；接收时也是在去除首部后就原封不动地交付上层的应用进程。</p></li></ul><p><img src="/2020/11/01/network_notes/35.png" alt="image-20201223010739066" style="zoom:40%;"></p><h4 id="6-5-传输控制协议TCP"><a href="#6-5-传输控制协议TCP" class="headerlink" title="6.5 传输控制协议TCP"></a>6.5 传输控制协议TCP</h4><ul><li>TCP 是面向连接的运输层协议，每一条 TCP 连接只能是点对点的；</li><li>TCP 提供可靠交付的服务；</li><li>TCP 提供全双工通信；</li><li>面向字节流；</li><li>TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）</li><li>TCP 连接的端点叫做套接字(socket)或插口；</li><li>端口号拼接到(contatenated with) IP 地址即构成了套接字</li></ul><p>自动重传请求ARQ：接收方不需要请求发送方重传某个出错的分组。</p><p><img src="/2020/11/01/network_notes/36.png" alt="image-20201223091104162" style="zoom:50%"></p><p>数据偏移：它指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位。</p><p>确认 ACK ： 只有当 ACK  1 时确认号字段才有效同步 </p><p>SYN ：同步 SYN = 1 表示这是一个连接请求或连接接受报文。 </p><p>检验和 ：占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在 TCP 报文段的前面加上 12 字节的伪首部</p><p>tcp默认使用累计确认的方法。</p><p>加权平均往返时间</p><h4 id="6-6-套接字Socket"><a href="#6-6-套接字Socket" class="headerlink" title="6.6 套接字Socket"></a>6.6 套接字Socket</h4><p><strong>套接字：</strong></p><p>每一条 TCP 连接唯一地被通信两端的两个端点（即两个套接字）所确定，对应公式：</p><script type="math/tex; mode=display">套接字 socket = (IP地址: 端口号)</script><p><strong>C/ S架构：</strong></p><p>CS即Client/Server（客户机/服务器）结构，C/S结构在技能上非常成熟，它的重要特征就是交互性强、拥有安全的存取形式、网络通信数量低、响应速度快、利于处置大量数据。可是这个结构的程序就是针对性开发，变更不够灵活，维护与管理的难度较大。常常只局限在小型局域网，不利于扩展。而且，因为这个结构的每台客户机全部须要安装相对应的客户端程序，分布功能弱并且兼容性差，不可以完成迅速部署安装与配置，因为这样缺少通用性，拥有比较大的局限性。请求拥有肯定专业水准的技能人员去结束。</p><h4 id="6-7-TCP"><a href="#6-7-TCP" class="headerlink" title="6.7 TCP"></a>6.7 TCP</h4><h5 id="6-7-3-拥塞控制"><a href="#6-7-3-拥塞控制" class="headerlink" title="6.7.3 拥塞控制"></a>6.7.3 拥塞控制</h5><p><img src="/2020/11/01/network_notes/37.png" alt="image-20201223143148194" style="zoom:40%;"></p><p>1、慢开始和拥塞避免</p><p><em>note：cwnd=1表示一个报文段，而一个报文段最大长度为MSS</em></p><p><em>传输轮次：发送一批报文段并收到确认的时间，一个往返时延RTT</em></p><p><img src="/2020/11/01/network_notes/38.png" alt="image-20201223143831142"></p><p>注意看图例的加法增大和乘法减小。</p><p>2、快重传和快恢复</p><p>快重传：收到三个冗余的确认就执行快重传（等不到RTT了）</p><p><img src="/2020/11/01/network_notes/39.png" alt="image-20201223144455902"></p><h3 id="第七章：应用层"><a href="#第七章：应用层" class="headerlink" title="第七章：应用层"></a>第七章：应用层</h3><p><img src="/2020/11/01/network_notes/40.png" alt="image-20201223143233111"></p><p><img src="/Users/liqilin/Library/Application Support/typora-user-images/image-20201223143309956.png" alt="image-20201223143309956"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;第一章-概述&quot;&gt;&lt;a href=&quot;#第一章-概述&quot; class=&quot;headerlink&quot; title=&quot;第一章 概述&quot;&gt;&lt;/a&gt;第一章 概述&lt;/h3&gt;&lt;h4 id=&quot;1-1-网络概念及分类&quot;&gt;&lt;a href=&quot;#1-1-网络概念及分类&quot; class=&quot;header</summary>
      
    
    
    
    <category term="Notes" scheme="http://example.com/categories/Notes/"/>
    
    
    <category term="Computer Networks" scheme="http://example.com/tags/Computer-Networks/"/>
    
  </entry>
  
</feed>
